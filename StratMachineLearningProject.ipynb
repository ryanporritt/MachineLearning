{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  carat      cut color clarity  depth  table  price     x     y  \\\n",
       "0           1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
       "1           2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
       "2           3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07   \n",
       "3           4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23   \n",
       "4           5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35   \n",
       "\n",
       "      z  \n",
       "0  2.43  \n",
       "1  2.31  \n",
       "2  2.31  \n",
       "3  2.63  \n",
       "4  2.75  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds = pd.read_csv('diamonds.csv')\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18823"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds[\"price\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds[\"price\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         326\n",
       "1         326\n",
       "2         327\n",
       "3         334\n",
       "4         335\n",
       "         ... \n",
       "53935    2757\n",
       "53936    2757\n",
       "53937    2757\n",
       "53938    2757\n",
       "53939    2757\n",
       "Name: price, Length: 53940, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bins for the Diamond Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins in which to place values based upon Diamond Price\n",
    "bins = [0, 499, 999, 2499, 4999, 7499, 9999, 14999, 19999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_groups = [1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for these bins\n",
    "group_labels = [\"0-500\", \"500-1000\", \"1000-2500\", \"2500-5000\", \"5000-7500\", \"7500-10000\", \"1000-15000\", \"15000-20000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  carat      cut color clarity  depth  table  price     x     y  \\\n",
       "0           1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
       "1           2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
       "2           3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07   \n",
       "3           4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23   \n",
       "4           5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35   \n",
       "\n",
       "      z bins  \n",
       "0  2.43    1  \n",
       "1  2.31    1  \n",
       "2  2.31    1  \n",
       "3  2.63    1  \n",
       "4  2.75    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice the data and place it into bins\n",
    "diamonds[\"bins\"] = pd.cut(diamonds[\"price\"], bins, labels=label_groups)\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratify the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    10788\n",
       "carat         10788\n",
       "cut           10788\n",
       "color         10788\n",
       "clarity       10788\n",
       "depth         10788\n",
       "table         10788\n",
       "price         10788\n",
       "x             10788\n",
       "y             10788\n",
       "z             10788\n",
       "bins          10788\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(diamonds, diamonds[\"bins\"]):\n",
    "    strat_train_set = diamonds.loc[train_index]\n",
    "    strat_test_set = diamonds.loc[test_index]\n",
    "\n",
    "strat_test_set.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>37140</td>\n",
       "      <td>37141</td>\n",
       "      <td>0.40</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>972</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38148</td>\n",
       "      <td>38149</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>I</td>\n",
       "      <td>VS1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1013</td>\n",
       "      <td>5.07</td>\n",
       "      <td>5.01</td>\n",
       "      <td>3.18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34466</td>\n",
       "      <td>34467</td>\n",
       "      <td>0.38</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>865</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.68</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14746</td>\n",
       "      <td>14747</td>\n",
       "      <td>1.14</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>VS2</td>\n",
       "      <td>61.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5937</td>\n",
       "      <td>6.72</td>\n",
       "      <td>6.68</td>\n",
       "      <td>4.13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10291</td>\n",
       "      <td>10292</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Premium</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4758</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.33</td>\n",
       "      <td>3.91</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17609</td>\n",
       "      <td>17610</td>\n",
       "      <td>1.02</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>VS1</td>\n",
       "      <td>60.7</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7091</td>\n",
       "      <td>6.53</td>\n",
       "      <td>6.61</td>\n",
       "      <td>3.99</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37819</td>\n",
       "      <td>37820</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>61.3</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1002</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.45</td>\n",
       "      <td>2.72</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11822</td>\n",
       "      <td>11823</td>\n",
       "      <td>1.12</td>\n",
       "      <td>Good</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>5094</td>\n",
       "      <td>6.72</td>\n",
       "      <td>6.85</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6315</td>\n",
       "      <td>6316</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4026</td>\n",
       "      <td>6.31</td>\n",
       "      <td>6.26</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23954</td>\n",
       "      <td>23955</td>\n",
       "      <td>1.64</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12089</td>\n",
       "      <td>7.57</td>\n",
       "      <td>7.59</td>\n",
       "      <td>4.71</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  carat        cut color clarity  depth  table  price     x  \\\n",
       "37140       37141   0.40  Very Good     F    VVS2   62.9   55.0    972  4.72   \n",
       "38148       38149   0.50  Very Good     I     VS1   63.1   56.0   1013  5.07   \n",
       "34466       34467   0.38      Ideal     F     VS1   62.0   54.0    865  4.65   \n",
       "14746       14747   1.14      Ideal     H     VS2   61.6   56.0   5937  6.72   \n",
       "10291       10292   1.00    Premium     D     SI2   61.6   60.0   4758  6.37   \n",
       "...           ...    ...        ...   ...     ...    ...    ...    ...   ...   \n",
       "17609       17610   1.02      Ideal     F     VS1   60.7   56.0   7091  6.53   \n",
       "37819       37820   0.32      Ideal     F    VVS2   61.3   56.0   1002  4.42   \n",
       "11822       11823   1.12       Good     H     SI1   59.8   61.0   5094  6.72   \n",
       "6315         6316   1.00       Good     E     SI2   64.0   54.0   4026  6.31   \n",
       "23954       23955   1.64      Ideal     I     VS1   62.1   55.0  12089  7.57   \n",
       "\n",
       "          y     z bins  \n",
       "37140  4.75  2.98    2  \n",
       "38148  5.01  3.18    3  \n",
       "34466  4.68  2.89    2  \n",
       "14746  6.68  4.13    5  \n",
       "10291  6.33  3.91    4  \n",
       "...     ...   ...  ...  \n",
       "17609  6.61  3.99    5  \n",
       "37819  4.45  2.72    3  \n",
       "11822  6.85  4.06    5  \n",
       "6315   6.26  4.01    4  \n",
       "23954  7.59  4.71    7  \n",
       "\n",
       "[53940 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [strat_train_set, strat_test_set]\n",
    "data = pd.concat(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53940, 4) (53940,)\n"
     ]
    }
   ],
   "source": [
    "X = data[[\"carat\", \"cut\", \"color\", \"clarity\"]]\n",
    "y = data[\"bins\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Encoding (Binary Encoded Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut_Fair</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>color_D</th>\n",
       "      <th>color_E</th>\n",
       "      <th>color_F</th>\n",
       "      <th>color_G</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_I1</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>37140</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38148</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34466</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14746</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10291</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  cut_Fair  cut_Good  cut_Ideal  cut_Premium  cut_Very Good  \\\n",
       "37140   0.40         0         0          0            0              1   \n",
       "38148   0.50         0         0          0            0              1   \n",
       "34466   0.38         0         0          1            0              0   \n",
       "14746   1.14         0         0          1            0              0   \n",
       "10291   1.00         0         0          0            1              0   \n",
       "\n",
       "       color_D  color_E  color_F  color_G  ...  color_I  color_J  clarity_I1  \\\n",
       "37140        0        0        1        0  ...        0        0           0   \n",
       "38148        0        0        0        0  ...        1        0           0   \n",
       "34466        0        0        1        0  ...        0        0           0   \n",
       "14746        0        0        0        0  ...        0        0           0   \n",
       "10291        1        0        0        0  ...        0        0           0   \n",
       "\n",
       "       clarity_IF  clarity_SI1  clarity_SI2  clarity_VS1  clarity_VS2  \\\n",
       "37140           0            0            0            0            0   \n",
       "38148           0            0            0            1            0   \n",
       "34466           0            0            0            1            0   \n",
       "14746           0            0            0            0            1   \n",
       "10291           0            0            1            0            0   \n",
       "\n",
       "       clarity_VVS1  clarity_VVS2  \n",
       "37140             0             1  \n",
       "38148             0             0  \n",
       "34466             0             0  \n",
       "14746             0             0  \n",
       "10291             0             0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = X.copy()\n",
    "\n",
    "data_binary_encoded = pd.get_dummies(data, columns=[\"cut\", \"color\", \"clarity\"])\n",
    "data_binary_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut_Fair</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>color_D</th>\n",
       "      <th>color_E</th>\n",
       "      <th>color_F</th>\n",
       "      <th>color_G</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_I1</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27234</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31867</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16980</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>778</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5731</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  cut_Fair  cut_Good  cut_Ideal  cut_Premium  cut_Very Good  \\\n",
       "27234   1.64         0         0          1            0              0   \n",
       "31867   0.30         0         0          0            1              0   \n",
       "16980   1.04         0         0          0            1              0   \n",
       "778     0.83         0         0          0            1              0   \n",
       "5731    1.09         0         0          0            0              1   \n",
       "\n",
       "       color_D  color_E  color_F  color_G  ...  color_I  color_J  clarity_I1  \\\n",
       "27234        0        0        0        1  ...        0        0           0   \n",
       "31867        0        0        0        0  ...        0        0           0   \n",
       "16980        0        0        1        0  ...        0        0           0   \n",
       "778          0        1        0        0  ...        0        0           0   \n",
       "5731         1        0        0        0  ...        0        0           0   \n",
       "\n",
       "       clarity_IF  clarity_SI1  clarity_SI2  clarity_VS1  clarity_VS2  \\\n",
       "27234           0            0            0            0            0   \n",
       "31867           0            0            0            0            0   \n",
       "16980           0            0            0            0            1   \n",
       "778             0            0            1            0            0   \n",
       "5731            0            0            1            0            0   \n",
       "\n",
       "       clarity_VVS1  clarity_VVS2  \n",
       "27234             0             1  \n",
       "31867             0             1  \n",
       "16980             0             0  \n",
       "778               0             0  \n",
       "5731              0             0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalization\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_binary_encoded\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [21,42,63, 126]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_count = [20,40,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_node_count = []\n",
    "train_data_accuracy = []\n",
    "train_data_loss = []\n",
    "train_data_epochs = []\n",
    "\n",
    "test_data_node_count = []\n",
    "test_data_accuracy = []\n",
    "test_data_loss = []\n",
    "test_data_epochs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Hidden Layers: \n",
      "\n",
      "Epochs count: 20 \n",
      "\n",
      "Model: 0\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 2s - loss: 0.3277 - acc: 0.8632\n",
      "Normal Neural Network - Loss: 0.32774063041722606, Train Data Accuracy: 0.8631812930107117  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3393 - acc: 0.8583\n",
      "Normal Neural Network - Loss: 0.339328736745299, Test Data Accuracy: 0.85828697681427 \n",
      "\n",
      "Model: 1\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 2s - loss: 0.3105 - acc: 0.8701\n",
      "Normal Neural Network - Loss: 0.3105373468096715, Train Data Accuracy: 0.8701273202896118  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3251 - acc: 0.8615\n",
      "Normal Neural Network - Loss: 0.3250605850041598, Test Data Accuracy: 0.8615498542785645 \n",
      "\n",
      "Model: 2\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 2s - loss: 0.3156 - acc: 0.8651\n",
      "Normal Neural Network - Loss: 0.3155823611561911, Train Data Accuracy: 0.8650599718093872  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3293 - acc: 0.8576\n",
      "Normal Neural Network - Loss: 0.32931366258411, Test Data Accuracy: 0.85761958360672 \n",
      "\n",
      "Model: 3\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 2s - loss: 0.3172 - acc: 0.8650\n",
      "Normal Neural Network - Loss: 0.31724575593995746, Train Data Accuracy: 0.8650104999542236  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3331 - acc: 0.8601\n",
      "Normal Neural Network - Loss: 0.33314344361728326, Test Data Accuracy: 0.8600667119026184 \n",
      "\n",
      "Epochs count: 40 \n",
      "\n",
      "Model: 4\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 2s - loss: 0.3110 - acc: 0.8694\n",
      "Normal Neural Network - Loss: 0.31097391499030314, Train Data Accuracy: 0.8693857192993164  \n",
      "\n",
      "13485/13485 - 0s - loss: 0.3297 - acc: 0.8589\n",
      "Normal Neural Network - Loss: 0.3296995127304952, Test Data Accuracy: 0.8588802218437195 \n",
      "\n",
      "Model: 5\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 2s - loss: 0.3193 - acc: 0.8674\n",
      "Normal Neural Network - Loss: 0.3193340976266834, Train Data Accuracy: 0.8673588037490845  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3358 - acc: 0.8584\n",
      "Normal Neural Network - Loss: 0.33584075144895764, Test Data Accuracy: 0.8583611249923706 \n",
      "\n",
      "Model: 6\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 2s - loss: 0.3064 - acc: 0.8695\n",
      "Normal Neural Network - Loss: 0.3064150896182595, Train Data Accuracy: 0.8694846034049988  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3266 - acc: 0.8599\n",
      "Normal Neural Network - Loss: 0.3265607285431062, Test Data Accuracy: 0.8599184155464172 \n",
      "\n",
      "Model: 7\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 3s - loss: 0.3100 - acc: 0.8698\n",
      "Normal Neural Network - Loss: 0.30997409380317664, Train Data Accuracy: 0.8697812557220459  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3285 - acc: 0.8615\n",
      "Normal Neural Network - Loss: 0.3285212532299114, Test Data Accuracy: 0.8614757061004639 \n",
      "\n",
      "Epochs count: 60 \n",
      "\n",
      "Model: 8\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 2s - loss: 0.3299 - acc: 0.8592\n",
      "Normal Neural Network - Loss: 0.3298518931124594, Train Data Accuracy: 0.8592016100883484  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3442 - acc: 0.8523\n",
      "Normal Neural Network - Loss: 0.344218938384712, Test Data Accuracy: 0.85228031873703 \n",
      "\n",
      "Model: 9\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 2s - loss: 0.3233 - acc: 0.8635\n",
      "Normal Neural Network - Loss: 0.3232586218479493, Train Data Accuracy: 0.863453209400177  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3423 - acc: 0.8553\n",
      "Normal Neural Network - Loss: 0.34232696095881393, Test Data Accuracy: 0.8553207516670227 \n",
      "\n",
      "Model: 10\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 3s - loss: 0.3186 - acc: 0.8677\n",
      "Normal Neural Network - Loss: 0.3186111623241055, Train Data Accuracy: 0.8676801323890686  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3364 - acc: 0.8605\n",
      "Normal Neural Network - Loss: 0.3364181444076507, Test Data Accuracy: 0.8605116605758667 \n",
      "\n",
      "Model: 11\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 3s - loss: 0.3086 - acc: 0.8668\n",
      "Normal Neural Network - Loss: 0.30864237906419806, Train Data Accuracy: 0.866765558719635  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3315 - acc: 0.8590\n",
      "Normal Neural Network - Loss: 0.33153328176202446, Test Data Accuracy: 0.8590285778045654 \n",
      "\n",
      "One Hidden Layer: \n",
      "\n",
      "Epochs count: 20 \n",
      "\n",
      "Model: 12\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 4s - loss: 0.3254 - acc: 0.8646\n",
      "Normal Neural Network - Loss: 0.3253616105816211, Train Data Accuracy: 0.8645655512809753  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3476 - acc: 0.8535\n",
      "Normal Neural Network - Loss: 0.3475621548435358, Test Data Accuracy: 0.8535409569740295 \n",
      "\n",
      "Model: 13\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 3s - loss: 0.3349 - acc: 0.8622\n",
      "Normal Neural Network - Loss: 0.33493743751019867, Train Data Accuracy: 0.8622173070907593  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3539 - acc: 0.8539\n",
      "Normal Neural Network - Loss: 0.3538628987385071, Test Data Accuracy: 0.8539117574691772 \n",
      "\n",
      "Model: 14\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 4s - loss: 0.3199 - acc: 0.8632\n",
      "Normal Neural Network - Loss: 0.319909449534781, Train Data Accuracy: 0.8631566166877747  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3414 - acc: 0.8551\n",
      "Normal Neural Network - Loss: 0.3413934257656369, Test Data Accuracy: 0.8550982475280762 \n",
      "\n",
      "Model: 15\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 5s - loss: 0.3497 - acc: 0.8557\n",
      "Normal Neural Network - Loss: 0.34973079772361526, Train Data Accuracy: 0.8556668162345886  \n",
      "\n",
      "13485/13485 - 2s - loss: 0.3705 - acc: 0.8501\n",
      "Normal Neural Network - Loss: 0.37052184142887834, Test Data Accuracy: 0.8500556349754333 \n",
      "\n",
      "Epochs count: 40 \n",
      "\n",
      "Model: 16\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 4s - loss: 0.3302 - acc: 0.8662\n",
      "Normal Neural Network - Loss: 0.33017368864886415, Train Data Accuracy: 0.8661723136901855  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3524 - acc: 0.8541\n",
      "Normal Neural Network - Loss: 0.3523761475466338, Test Data Accuracy: 0.854134202003479 \n",
      "\n",
      "Model: 17\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 4s - loss: 0.3274 - acc: 0.8607\n",
      "Normal Neural Network - Loss: 0.3274370106568134, Train Data Accuracy: 0.8606600165367126  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3435 - acc: 0.8524\n",
      "Normal Neural Network - Loss: 0.34345293005926325, Test Data Accuracy: 0.8524286150932312 \n",
      "\n",
      "Model: 18\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 5s - loss: 0.4132 - acc: 0.8364\n",
      "Normal Neural Network - Loss: 0.41321555452299064, Train Data Accuracy: 0.8364108204841614  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.4298 - acc: 0.8294\n",
      "Normal Neural Network - Loss: 0.4297579468357417, Test Data Accuracy: 0.8293659687042236 \n",
      "\n",
      "Model: 19\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 5s - loss: 0.6093 - acc: 0.7300\n",
      "Normal Neural Network - Loss: 0.6092506843655767, Train Data Accuracy: 0.7299962639808655  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.6194 - acc: 0.7265\n",
      "Normal Neural Network - Loss: 0.6193570784740993, Test Data Accuracy: 0.7265109419822693 \n",
      "\n",
      "Epochs count: 60 \n",
      "\n",
      "Model: 20\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 5s - loss: 1.7948 - acc: 0.2644\n",
      "Normal Neural Network - Loss: 1.794847069581055, Train Data Accuracy: 0.26444196701049805  \n",
      "\n",
      "13485/13485 - 2s - loss: 1.8028 - acc: 0.2641\n",
      "Normal Neural Network - Loss: 1.802838666482373, Test Data Accuracy: 0.26407119631767273 \n",
      "\n",
      "Model: 21\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 6s - loss: 1.7810 - acc: 0.2685\n",
      "Normal Neural Network - Loss: 1.781028191348764, Train Data Accuracy: 0.2685452997684479  \n",
      "\n",
      "13485/13485 - 2s - loss: 1.7905 - acc: 0.2634\n",
      "Normal Neural Network - Loss: 1.790514993252116, Test Data Accuracy: 0.2634037733078003 \n",
      "\n",
      "Model: 22\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 6s - loss: 1.7810 - acc: 0.2726\n",
      "Normal Neural Network - Loss: 1.7810425956675626, Train Data Accuracy: 0.27257445454597473  \n",
      "\n",
      "13485/13485 - 2s - loss: 1.7902 - acc: 0.2713\n",
      "Normal Neural Network - Loss: 1.7902233631645348, Test Data Accuracy: 0.2713385224342346 \n",
      "\n",
      "Model: 23\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 7s - loss: 1.7817 - acc: 0.2726\n",
      "Normal Neural Network - Loss: 1.781670246677071, Train Data Accuracy: 0.27257445454597473  \n",
      "\n",
      "13485/13485 - 2s - loss: 1.7912 - acc: 0.2713\n",
      "Normal Neural Network - Loss: 1.7911529930865804, Test Data Accuracy: 0.2713385224342346 \n",
      "\n",
      "Two Hidden Layers: \n",
      "\n",
      "Epochs count: 20 \n",
      "\n",
      "Model: 24\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 14s - loss: 1.7818 - acc: 0.2685\n",
      "Deep Learning - Loss: 1.7817911879681285, Train Data Accuracy: 0.2685452997684479  \n",
      "\n",
      "13485/13485 - 4s - loss: 1.7913 - acc: 0.2634\n",
      "Deep Learning - Loss: 1.7912526394819657, Test Data Accuracy: 0.2634037733078003 \n",
      "\n",
      "Model: 25\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 15s - loss: 1.7823 - acc: 0.2685\n",
      "Deep Learning - Loss: 1.7823140606392802, Train Data Accuracy: 0.2685452997684479  \n",
      "\n",
      "13485/13485 - 4s - loss: 1.7917 - acc: 0.2634\n",
      "Deep Learning - Loss: 1.791726251058681, Test Data Accuracy: 0.2634037733078003 \n",
      "\n",
      "Model: 26\n",
      "Number of Nodes: 63 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40455/40455 - 15s - loss: 1.7820 - acc: 0.2726\n",
      "Deep Learning - Loss: 1.7820360032019016, Train Data Accuracy: 0.27257445454597473  \n",
      "\n",
      "13485/13485 - 4s - loss: 1.7917 - acc: 0.2713\n",
      "Deep Learning - Loss: 1.7916671554733745, Test Data Accuracy: 0.2713385224342346 \n",
      "\n",
      "Model: 27\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 16s - loss: 1.7829 - acc: 0.2726\n",
      "Deep Learning - Loss: 1.7828510897163408, Train Data Accuracy: 0.27257445454597473  \n",
      "\n",
      "13485/13485 - 5s - loss: 1.7912 - acc: 0.2713\n",
      "Deep Learning - Loss: 1.7912340021681512, Test Data Accuracy: 0.2713385224342346 \n",
      "\n",
      "Epochs count: 40 \n",
      "\n",
      "Model: 28\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 17s - loss: 1.7812 - acc: 0.2726\n",
      "Deep Learning - Loss: 1.781232449504799, Train Data Accuracy: 0.27257445454597473  \n",
      "\n",
      "13485/13485 - 5s - loss: 1.7904 - acc: 0.2713\n",
      "Deep Learning - Loss: 1.7904027706347088, Test Data Accuracy: 0.2713385224342346 \n",
      "\n",
      "Model: 29\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 18s - loss: 1.7809 - acc: 0.2685\n",
      "Deep Learning - Loss: 1.7808992074927064, Train Data Accuracy: 0.2685452997684479  \n",
      "\n",
      "13485/13485 - 6s - loss: 1.7903 - acc: 0.2634\n",
      "Deep Learning - Loss: 1.7902500097955825, Test Data Accuracy: 0.2634037733078003 \n",
      "\n",
      "Model: 30\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 20s - loss: 1.7810 - acc: 0.2685\n",
      "Deep Learning - Loss: 1.7809956770717634, Train Data Accuracy: 0.2685452997684479  \n",
      "\n",
      "13485/13485 - 6s - loss: 1.7902 - acc: 0.2634\n",
      "Deep Learning - Loss: 1.79021331284459, Test Data Accuracy: 0.2634037733078003 \n",
      "\n",
      "Model: 31\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 21s - loss: 1.7812 - acc: 0.2685\n",
      "Deep Learning - Loss: 1.7812283932949053, Train Data Accuracy: 0.2685452997684479  \n",
      "\n",
      "13485/13485 - 7s - loss: 1.7906 - acc: 0.2634\n",
      "Deep Learning - Loss: 1.790610160976151, Test Data Accuracy: 0.2634037733078003 \n",
      "\n",
      "Epochs count: 60 \n",
      "\n",
      "Model: 32\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 23s - loss: 1.7810 - acc: 0.2685\n",
      "Deep Learning - Loss: 1.7810447353173975, Train Data Accuracy: 0.2685452997684479  \n",
      "\n",
      "13485/13485 - 7s - loss: 1.7904 - acc: 0.2634\n",
      "Deep Learning - Loss: 1.790361518156188, Test Data Accuracy: 0.2634037733078003 \n",
      "\n",
      "Model: 33\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 24s - loss: 1.7812 - acc: 0.2685\n",
      "Deep Learning - Loss: 1.7812146536485622, Train Data Accuracy: 0.2685452997684479  \n",
      "\n",
      "13485/13485 - 7s - loss: 1.7909 - acc: 0.2634\n",
      "Deep Learning - Loss: 1.7909100631718111, Test Data Accuracy: 0.2634037733078003 \n",
      "\n",
      "Model: 34\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 25s - loss: 1.7811 - acc: 0.2726\n",
      "Deep Learning - Loss: 1.7810548576373368, Train Data Accuracy: 0.27257445454597473  \n",
      "\n",
      "13485/13485 - 7s - loss: 1.7900 - acc: 0.2713\n",
      "Deep Learning - Loss: 1.789996397570411, Test Data Accuracy: 0.2713385224342346 \n",
      "\n",
      "Model: 35\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 27s - loss: 1.7810 - acc: 0.2685\n",
      "Deep Learning - Loss: 1.7810099704232296, Train Data Accuracy: 0.2685452997684479  \n",
      "\n",
      "13485/13485 - 8s - loss: 1.7904 - acc: 0.2634\n",
      "Deep Learning - Loss: 1.7903512175541965, Test Data Accuracy: 0.2634037733078003 \n",
      "\n",
      "Train Data Node Count: [21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126] \n",
      "\n",
      "Train Data Accuracy: [0.8626622, 0.8683475, 0.8651094, 0.8678284, 0.8684959, 0.86876774, 0.8661723, 0.8651341, 0.86748236, 0.8678779, 0.8681251, 0.8631813, 0.8701273, 0.86506, 0.8650105, 0.8693857, 0.8673588, 0.8694846, 0.86978126, 0.8592016, 0.8634532, 0.86768013, 0.86676556, 0.86456555, 0.8622173, 0.8631566, 0.8556668, 0.8661723, 0.86066, 0.8364108, 0.72999626, 0.26444197, 0.2685453, 0.27257445, 0.27257445, 0.2685453, 0.2685453, 0.27257445, 0.27257445, 0.27257445, 0.2685453, 0.2685453, 0.2685453, 0.2685453, 0.2685453, 0.27257445, 0.2685453] \n",
      "\n",
      "Train Data Data Loss: [0.3262383237792364, 0.3145966818992441, 0.3158007027398316, 0.3136967333649958, 0.30684665366224534, 0.3081080042053221, 0.31321748919723325, 0.3121634937087061, 0.3102052033249578, 0.3071286787298403, 0.30844839940096447, 0.32774063041722606, 0.3105373468096715, 0.3155823611561911, 0.31724575593995746, 0.31097391499030314, 0.3193340976266834, 0.3064150896182595, 0.30997409380317664, 0.3298518931124594, 0.3232586218479493, 0.3186111623241055, 0.30864237906419806, 0.3253616105816211, 0.33493743751019867, 0.319909449534781, 0.34973079772361526, 0.33017368864886415, 0.3274370106568134, 0.41321555452299064, 0.6092506843655767, 1.794847069581055, 1.781028191348764, 1.7810425956675626, 1.781670246677071, 1.7817911879681285, 1.7823140606392802, 1.7820360032019016, 1.7828510897163408, 1.781232449504799, 1.7808992074927064, 1.7809956770717634, 1.7812283932949053, 1.7810447353173975, 1.7812146536485622, 1.7810548576373368, 1.7810099704232296] \n",
      "\n",
      "Train Data Epochs Count: [20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60] \n",
      "\n",
      "Test Data Node Count: [21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126] \n",
      "\n",
      "Test Data Accuracy: [0.85480165, 0.8623656, 0.85598814, 0.8613274, 0.8596218, 0.86192065, 0.85650724, 0.8562106, 0.8585836, 0.8590286, 0.8597701, 0.858287, 0.86154985, 0.8576196, 0.8600667, 0.8588802, 0.8583611, 0.8599184, 0.8614757, 0.8522803, 0.85532075, 0.86051166, 0.8590286, 0.85354096, 0.85391176, 0.85509825, 0.85005563, 0.8541342, 0.8524286, 0.82936597, 0.72651094, 0.2640712, 0.26340377, 0.27133852, 0.27133852, 0.26340377, 0.26340377, 0.27133852, 0.27133852, 0.27133852, 0.26340377, 0.26340377, 0.26340377, 0.26340377, 0.26340377, 0.27133852, 0.26340377] \n",
      "\n",
      "Test Data Data Loss: [0.33973346168923296, 0.3280890412228082, 0.3315661991298928, 0.33061241295035343, 0.3278531417234058, 0.3284033278005407, 0.33649617068892196, 0.3312532730044194, 0.33404328068915146, 0.3303893713894534, 0.33388700620925643, 0.339328736745299, 0.3250605850041598, 0.32931366258411, 0.33314344361728326, 0.3296995127304952, 0.33584075144895764, 0.3265607285431062, 0.3285212532299114, 0.344218938384712, 0.34232696095881393, 0.3364181444076507, 0.33153328176202446, 0.3475621548435358, 0.3538628987385071, 0.3413934257656369, 0.37052184142887834, 0.3523761475466338, 0.34345293005926325, 0.4297579468357417, 0.6193570784740993, 1.802838666482373, 1.790514993252116, 1.7902233631645348, 1.7911529930865804, 1.7912526394819657, 1.791726251058681, 1.7916671554733745, 1.7912340021681512, 1.7904027706347088, 1.7902500097955825, 1.79021331284459, 1.790610160976151, 1.790361518156188, 1.7909100631718111, 1.789996397570411, 1.7903512175541965] \n",
      "\n",
      "Test Data Epochs Count: [20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "\n",
    "k = 0\n",
    "\n",
    "for i in range(3):\n",
    "    count = nodes[i]\n",
    "    \n",
    "    if i == 0:\n",
    "        print(\"No Hidden Layers: \\n\")\n",
    "        for j in range(3):\n",
    "            current_epochs_count = epochs_count[j]\n",
    "\n",
    "            print(f\"Epochs count: {current_epochs_count} \\n\")\n",
    "            for i in range(len(nodes)):\n",
    "                print(f\"Model: {k}\")\n",
    "                #create 4 models with varying node sizes 21,42,63,126\n",
    "                model.add(Dense(units=count, activation='relu', input_dim=21))\n",
    "                model.add(Dense(units=9, activation='softmax'))\n",
    "                #print(model.summary())\n",
    "\n",
    "                # Compile the model\n",
    "                model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "                # Fit the model to the training data\n",
    "                model.fit(\n",
    "                    X_train_scaled,\n",
    "                    y_train_categorical,\n",
    "                    epochs=current_epochs_count,\n",
    "                    shuffle=True,\n",
    "                    verbose=0\n",
    "                )\n",
    "\n",
    "                # Print the number of nodes for this model\n",
    "                print(f\"Number of Nodes: {nodes[i]} \\n\")\n",
    "\n",
    "                # Print the training data accuracy\n",
    "                model_loss, model_accuracy = model.evaluate(X_train_scaled, y_train_categorical, verbose=2)\n",
    "                print(f\"Normal Neural Network - Loss: {model_loss}, Train Data Accuracy: {model_accuracy}  \\n\")\n",
    "\n",
    "                # Append aquired data to lists\n",
    "                train_data_node_count.append(nodes[i])\n",
    "                train_data_accuracy.append(model_accuracy)\n",
    "                train_data_loss.append(model_loss)\n",
    "                train_data_epochs.append(current_epochs_count)\n",
    "\n",
    "                # Print the test data accuracy\n",
    "                model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "                print(f\"Normal Neural Network - Loss: {model_loss}, Test Data Accuracy: {model_accuracy} \\n\")\n",
    "\n",
    "                # Append aquired data to lists\n",
    "                test_data_node_count.append(nodes[i])\n",
    "                test_data_accuracy.append(model_accuracy)\n",
    "                test_data_loss.append(model_loss)\n",
    "                test_data_epochs.append(current_epochs_count)\n",
    "                \n",
    "                # Save the Model\n",
    "                model.save(f\"Models/strat_diamond_model{k}_trained.h5\")\n",
    "                k += 1\n",
    "            \n",
    "            \n",
    "    if i == 1:\n",
    "        print(\"One Hidden Layer: \\n\")\n",
    "        for j in range(3):\n",
    "            current_epochs_count = epochs_count[j]\n",
    "\n",
    "            print(f\"Epochs count: {current_epochs_count} \\n\")\n",
    "            for i in range(len(nodes)):\n",
    "                print(f\"Model: {k}\")\n",
    "                model.add(Dense(units=count, activation='relu', input_dim=21))\n",
    "                model.add(Dense(units=count, activation='relu'))\n",
    "                model.add(Dense(units=9, activation='softmax'))\n",
    "                #print(model.summary())\n",
    "\n",
    "                # Compile the model\n",
    "                model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "                # Fit the model to the training data\n",
    "                model.fit(\n",
    "                    X_train_scaled,\n",
    "                    y_train_categorical,\n",
    "                    epochs=current_epochs_count,\n",
    "                    shuffle=True,\n",
    "                    verbose=0\n",
    "                )\n",
    "\n",
    "                # Print the number of nodes for this model\n",
    "                print(f\"Number of Nodes: {nodes[i]} \\n\")\n",
    "\n",
    "                # Print the training data accuracy\n",
    "                model_loss, model_accuracy = model.evaluate(X_train_scaled, y_train_categorical, verbose=2)\n",
    "                print(f\"Normal Neural Network - Loss: {model_loss}, Train Data Accuracy: {model_accuracy}  \\n\")\n",
    "\n",
    "                # Append aquired data to lists\n",
    "                train_data_node_count.append(nodes[i])\n",
    "                train_data_accuracy.append(model_accuracy)\n",
    "                train_data_loss.append(model_loss)\n",
    "                train_data_epochs.append(current_epochs_count)\n",
    "\n",
    "                # Print the test data accuracy\n",
    "                model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "                print(f\"Normal Neural Network - Loss: {model_loss}, Test Data Accuracy: {model_accuracy} \\n\")\n",
    "\n",
    "                # Append aquired data to lists\n",
    "                test_data_node_count.append(nodes[i])\n",
    "                test_data_accuracy.append(model_accuracy)\n",
    "                test_data_loss.append(model_loss)\n",
    "                test_data_epochs.append(current_epochs_count)\n",
    "                \n",
    "                # Save the Model\n",
    "                model.save(f\"Models/strat_diamond_model{k}_trained.h5\")\n",
    "                k += 1\n",
    "    \n",
    "    if i == 2:\n",
    "        print(\"Two Hidden Layers: \\n\")\n",
    "        for j in range(3):\n",
    "            current_epochs_count = epochs_count[j]\n",
    "\n",
    "            print(f\"Epochs count: {current_epochs_count} \\n\")\n",
    "            for i in range(len(nodes)):\n",
    "                print(f\"Model: {k}\")\n",
    "\n",
    "                model.add(Dense(units=count, activation='relu', input_dim=21))\n",
    "                model.add(Dense(units=count, activation='relu'))\n",
    "                model.add(Dense(units=count, activation='relu'))\n",
    "                model.add(Dense(units=9, activation='softmax'))\n",
    "                #print(model.summary())\n",
    "\n",
    "                # Compile the model\n",
    "                model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "                # Fit the model to the training data\n",
    "                model.fit(\n",
    "                    X_train_scaled,\n",
    "                    y_train_categorical,\n",
    "                    epochs=current_epochs_count,\n",
    "                    shuffle=True,\n",
    "                    verbose=0\n",
    "                )\n",
    "\n",
    "                # Print the number of nodes for this model\n",
    "                print(f\"Number of Nodes: {nodes[i]} \\n\")\n",
    "\n",
    "                # Print the training data accuracy\n",
    "                model_loss, model_accuracy = model.evaluate(X_train_scaled, y_train_categorical, verbose=2)\n",
    "                print(f\"Deep Learning - Loss: {model_loss}, Train Data Accuracy: {model_accuracy}  \\n\")\n",
    "\n",
    "                # Append aquired data to lists\n",
    "                train_data_node_count.append(nodes[i])\n",
    "                train_data_accuracy.append(model_accuracy)\n",
    "                train_data_loss.append(model_loss)\n",
    "                train_data_epochs.append(current_epochs_count)\n",
    "\n",
    "                # Print the test data accuracy\n",
    "                model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "                print(f\"Deep Learning - Loss: {model_loss}, Test Data Accuracy: {model_accuracy} \\n\")\n",
    "\n",
    "                # Append aquired data to lists\n",
    "                test_data_node_count.append(nodes[i])\n",
    "                test_data_accuracy.append(model_accuracy)\n",
    "                test_data_loss.append(model_loss)\n",
    "                test_data_epochs.append(current_epochs_count)\n",
    "                \n",
    "                # Save the Model\n",
    "                model.save(f\"Models/strat_diamond_model{k}_trained.h5\")\n",
    "                k += 1\n",
    "                \n",
    "# Print the lists\n",
    "print(f\"Train Data Node Count: {train_data_node_count} \\n\")\n",
    "print(f\"Train Data Accuracy: {train_data_accuracy} \\n\")\n",
    "print(f\"Train Data Data Loss: {train_data_loss} \\n\")\n",
    "print(f\"Train Data Epochs Count: {train_data_epochs} \\n\")\n",
    "\n",
    "print(f\"Test Data Node Count: {test_data_node_count} \\n\")\n",
    "print(f\"Test Data Accuracy: {test_data_accuracy} \\n\")\n",
    "print(f\"Test Data Data Loss: {test_data_loss} \\n\")\n",
    "print(f\"Test Data Epochs Count: {test_data_epochs} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Node Count: [21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126] \n",
      "\n",
      "Train Data Accuracy: [0.8626622, 0.8683475, 0.8651094, 0.8678284, 0.8684959, 0.86876774, 0.8661723, 0.8651341, 0.86748236, 0.8678779, 0.8681251, 0.8631813, 0.8701273, 0.86506, 0.8650105, 0.8693857, 0.8673588, 0.8694846, 0.86978126, 0.8592016, 0.8634532, 0.86768013, 0.86676556, 0.86456555, 0.8622173, 0.8631566, 0.8556668, 0.8661723, 0.86066, 0.8364108, 0.72999626, 0.26444197, 0.2685453, 0.27257445, 0.27257445, 0.2685453, 0.2685453, 0.27257445, 0.27257445, 0.27257445, 0.2685453, 0.2685453, 0.2685453, 0.2685453, 0.2685453, 0.27257445, 0.2685453] \n",
      "\n",
      "Train Data Data Loss: [0.3262383237792364, 0.3145966818992441, 0.3158007027398316, 0.3136967333649958, 0.30684665366224534, 0.3081080042053221, 0.31321748919723325, 0.3121634937087061, 0.3102052033249578, 0.3071286787298403, 0.30844839940096447, 0.32774063041722606, 0.3105373468096715, 0.3155823611561911, 0.31724575593995746, 0.31097391499030314, 0.3193340976266834, 0.3064150896182595, 0.30997409380317664, 0.3298518931124594, 0.3232586218479493, 0.3186111623241055, 0.30864237906419806, 0.3253616105816211, 0.33493743751019867, 0.319909449534781, 0.34973079772361526, 0.33017368864886415, 0.3274370106568134, 0.41321555452299064, 0.6092506843655767, 1.794847069581055, 1.781028191348764, 1.7810425956675626, 1.781670246677071, 1.7817911879681285, 1.7823140606392802, 1.7820360032019016, 1.7828510897163408, 1.781232449504799, 1.7808992074927064, 1.7809956770717634, 1.7812283932949053, 1.7810447353173975, 1.7812146536485622, 1.7810548576373368, 1.7810099704232296] \n",
      "\n",
      "Train Data Epochs Count: [20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60] \n",
      "\n",
      "Test Data Node Count: [21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126] \n",
      "\n",
      "Test Data Accuracy: [0.85480165, 0.8623656, 0.85598814, 0.8613274, 0.8596218, 0.86192065, 0.85650724, 0.8562106, 0.8585836, 0.8590286, 0.8597701, 0.858287, 0.86154985, 0.8576196, 0.8600667, 0.8588802, 0.8583611, 0.8599184, 0.8614757, 0.8522803, 0.85532075, 0.86051166, 0.8590286, 0.85354096, 0.85391176, 0.85509825, 0.85005563, 0.8541342, 0.8524286, 0.82936597, 0.72651094, 0.2640712, 0.26340377, 0.27133852, 0.27133852, 0.26340377, 0.26340377, 0.27133852, 0.27133852, 0.27133852, 0.26340377, 0.26340377, 0.26340377, 0.26340377, 0.26340377, 0.27133852, 0.26340377] \n",
      "\n",
      "Test Data Data Loss: [0.33973346168923296, 0.3280890412228082, 0.3315661991298928, 0.33061241295035343, 0.3278531417234058, 0.3284033278005407, 0.33649617068892196, 0.3312532730044194, 0.33404328068915146, 0.3303893713894534, 0.33388700620925643, 0.339328736745299, 0.3250605850041598, 0.32931366258411, 0.33314344361728326, 0.3296995127304952, 0.33584075144895764, 0.3265607285431062, 0.3285212532299114, 0.344218938384712, 0.34232696095881393, 0.3364181444076507, 0.33153328176202446, 0.3475621548435358, 0.3538628987385071, 0.3413934257656369, 0.37052184142887834, 0.3523761475466338, 0.34345293005926325, 0.4297579468357417, 0.6193570784740993, 1.802838666482373, 1.790514993252116, 1.7902233631645348, 1.7911529930865804, 1.7912526394819657, 1.791726251058681, 1.7916671554733745, 1.7912340021681512, 1.7904027706347088, 1.7902500097955825, 1.79021331284459, 1.790610160976151, 1.790361518156188, 1.7909100631718111, 1.789996397570411, 1.7903512175541965] \n",
      "\n",
      "Test Data Epochs Count: [20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the lists\n",
    "print(f\"Train Data Node Count: {train_data_node_count} \\n\")\n",
    "print(f\"Train Data Accuracy: {train_data_accuracy} \\n\")\n",
    "print(f\"Train Data Data Loss: {train_data_loss} \\n\")\n",
    "print(f\"Train Data Epochs Count: {train_data_epochs} \\n\")\n",
    "print(f\"Test Data Node Count: {test_data_node_count} \\n\")\n",
    "print(f\"Test Data Accuracy: {test_data_accuracy} \\n\")\n",
    "print(f\"Test Data Data Loss: {test_data_loss} \\n\")\n",
    "print(f\"Test Data Epochs Count: {test_data_epochs} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nodes = [21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 42, 84, 126, 252, 42, 84, 126, 252, 42, 84, 126, 252,63, 126, 189, 378, 63, 126, 189, 378, 63, 126, 189, 378]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_node_count = [21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126] \n",
    "\n",
    "train_data_accuracy = [0.8631813, 0.8701273, 0.86506, 0.8650105, 0.8693857, 0.8673588, 0.8694846, 0.86978126, 0.8592016, 0.8634532, 0.86768013, 0.86676556, 0.86456555, 0.8622173, 0.8631566, 0.8556668, 0.8661723, 0.86066, 0.8364108, 0.72999626, 0.26444197, 0.2685453, 0.27257445, 0.27257445, 0.2685453, 0.2685453, 0.27257445, 0.27257445, 0.27257445, 0.2685453, 0.2685453, 0.2685453, 0.2685453, 0.2685453, 0.27257445, 0.2685453] \n",
    "\n",
    "train_data_loss = [0.32774063041722606, 0.3105373468096715, 0.3155823611561911, 0.31724575593995746, 0.31097391499030314, 0.3193340976266834, 0.3064150896182595, 0.30997409380317664, 0.3298518931124594, 0.3232586218479493, 0.3186111623241055, 0.30864237906419806, 0.3253616105816211, 0.33493743751019867, 0.319909449534781, 0.34973079772361526, 0.33017368864886415, 0.3274370106568134, 0.41321555452299064, 0.6092506843655767, 1.794847069581055, 1.781028191348764, 1.7810425956675626, 1.781670246677071, 1.7817911879681285, 1.7823140606392802, 1.7820360032019016, 1.7828510897163408, 1.781232449504799, 1.7808992074927064, 1.7809956770717634, 1.7812283932949053, 1.7810447353173975, 1.7812146536485622, 1.7810548576373368, 1.7810099704232296]  \n",
    "\n",
    "train_data_epochs = [20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60]\n",
    "\n",
    "test_data_node_count = [21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126] \n",
    "\n",
    "test_data_accuracy = [0.858287, 0.86154985, 0.8576196, 0.8600667, 0.8588802, 0.8583611, 0.8599184, 0.8614757, 0.8522803, 0.85532075, 0.86051166, 0.8590286, 0.85354096, 0.85391176, 0.85509825, 0.85005563, 0.8541342, 0.8524286, 0.82936597, 0.72651094, 0.2640712, 0.26340377, 0.27133852, 0.27133852, 0.26340377, 0.26340377, 0.27133852, 0.27133852, 0.27133852, 0.26340377, 0.26340377, 0.26340377, 0.26340377, 0.26340377, 0.27133852, 0.26340377] \n",
    "\n",
    "test_data_loss = [0.339328736745299, 0.3250605850041598, 0.32931366258411, 0.33314344361728326, 0.3296995127304952, 0.33584075144895764, 0.3265607285431062, 0.3285212532299114, 0.344218938384712, 0.34232696095881393, 0.3364181444076507, 0.33153328176202446, 0.3475621548435358, 0.3538628987385071, 0.3413934257656369, 0.37052184142887834, 0.3523761475466338, 0.34345293005926325, 0.4297579468357417, 0.6193570784740993, 1.802838666482373, 1.790514993252116, 1.7902233631645348, 1.7911529930865804, 1.7912526394819657, 1.791726251058681, 1.7916671554733745, 1.7912340021681512, 1.7904027706347088, 1.7902500097955825, 1.79021331284459, 1.790610160976151, 1.790361518156188, 1.7909100631718111, 1.789996397570411, 1.7903512175541965]  \n",
    "\n",
    "test_data_epochs = [20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train epochs node count loss acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Epochs Count</th>\n",
       "      <th>Total Node Count</th>\n",
       "      <th>Train Data Node Count</th>\n",
       "      <th>Train Data Loss</th>\n",
       "      <th>Train Data Accuracy</th>\n",
       "      <th>Test Data Loss</th>\n",
       "      <th>Test Data Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0.327741</td>\n",
       "      <td>0.863181</td>\n",
       "      <td>0.339329</td>\n",
       "      <td>0.858287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.310537</td>\n",
       "      <td>0.870127</td>\n",
       "      <td>0.325061</td>\n",
       "      <td>0.861550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.315582</td>\n",
       "      <td>0.865060</td>\n",
       "      <td>0.329314</td>\n",
       "      <td>0.857620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>0.317246</td>\n",
       "      <td>0.865011</td>\n",
       "      <td>0.333143</td>\n",
       "      <td>0.860067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0.310974</td>\n",
       "      <td>0.869386</td>\n",
       "      <td>0.329700</td>\n",
       "      <td>0.858880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.319334</td>\n",
       "      <td>0.867359</td>\n",
       "      <td>0.335841</td>\n",
       "      <td>0.858361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.306415</td>\n",
       "      <td>0.869485</td>\n",
       "      <td>0.326561</td>\n",
       "      <td>0.859918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>0.309974</td>\n",
       "      <td>0.869781</td>\n",
       "      <td>0.328521</td>\n",
       "      <td>0.861476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0.329852</td>\n",
       "      <td>0.859202</td>\n",
       "      <td>0.344219</td>\n",
       "      <td>0.852280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.323259</td>\n",
       "      <td>0.863453</td>\n",
       "      <td>0.342327</td>\n",
       "      <td>0.855321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.318611</td>\n",
       "      <td>0.867680</td>\n",
       "      <td>0.336418</td>\n",
       "      <td>0.860512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>0.308642</td>\n",
       "      <td>0.866766</td>\n",
       "      <td>0.331533</td>\n",
       "      <td>0.859029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>0.325362</td>\n",
       "      <td>0.864566</td>\n",
       "      <td>0.347562</td>\n",
       "      <td>0.853541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "      <td>0.334937</td>\n",
       "      <td>0.862217</td>\n",
       "      <td>0.353863</td>\n",
       "      <td>0.853912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>126</td>\n",
       "      <td>63</td>\n",
       "      <td>0.319909</td>\n",
       "      <td>0.863157</td>\n",
       "      <td>0.341393</td>\n",
       "      <td>0.855098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>252</td>\n",
       "      <td>126</td>\n",
       "      <td>0.349731</td>\n",
       "      <td>0.855667</td>\n",
       "      <td>0.370522</td>\n",
       "      <td>0.850056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>0.330174</td>\n",
       "      <td>0.866172</td>\n",
       "      <td>0.352376</td>\n",
       "      <td>0.854134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "      <td>0.327437</td>\n",
       "      <td>0.860660</td>\n",
       "      <td>0.343453</td>\n",
       "      <td>0.852429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>126</td>\n",
       "      <td>63</td>\n",
       "      <td>0.413216</td>\n",
       "      <td>0.836411</td>\n",
       "      <td>0.429758</td>\n",
       "      <td>0.829366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>252</td>\n",
       "      <td>126</td>\n",
       "      <td>0.609251</td>\n",
       "      <td>0.729996</td>\n",
       "      <td>0.619357</td>\n",
       "      <td>0.726511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>1.794847</td>\n",
       "      <td>0.264442</td>\n",
       "      <td>1.802839</td>\n",
       "      <td>0.264071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "      <td>1.781028</td>\n",
       "      <td>0.268545</td>\n",
       "      <td>1.790515</td>\n",
       "      <td>0.263404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>126</td>\n",
       "      <td>63</td>\n",
       "      <td>1.781043</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>1.790223</td>\n",
       "      <td>0.271339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>252</td>\n",
       "      <td>126</td>\n",
       "      <td>1.781670</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>1.791153</td>\n",
       "      <td>0.271339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>21</td>\n",
       "      <td>1.781791</td>\n",
       "      <td>0.268545</td>\n",
       "      <td>1.791253</td>\n",
       "      <td>0.263404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>1.782314</td>\n",
       "      <td>0.268545</td>\n",
       "      <td>1.791726</td>\n",
       "      <td>0.263404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>189</td>\n",
       "      <td>63</td>\n",
       "      <td>1.782036</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>1.791667</td>\n",
       "      <td>0.271339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>378</td>\n",
       "      <td>126</td>\n",
       "      <td>1.782851</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>1.791234</td>\n",
       "      <td>0.271339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>21</td>\n",
       "      <td>1.781232</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>1.790403</td>\n",
       "      <td>0.271339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>1.780899</td>\n",
       "      <td>0.268545</td>\n",
       "      <td>1.790250</td>\n",
       "      <td>0.263404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>189</td>\n",
       "      <td>63</td>\n",
       "      <td>1.780996</td>\n",
       "      <td>0.268545</td>\n",
       "      <td>1.790213</td>\n",
       "      <td>0.263404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>378</td>\n",
       "      <td>126</td>\n",
       "      <td>1.781228</td>\n",
       "      <td>0.268545</td>\n",
       "      <td>1.790610</td>\n",
       "      <td>0.263404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>21</td>\n",
       "      <td>1.781045</td>\n",
       "      <td>0.268545</td>\n",
       "      <td>1.790362</td>\n",
       "      <td>0.263404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>1.781215</td>\n",
       "      <td>0.268545</td>\n",
       "      <td>1.790910</td>\n",
       "      <td>0.263404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>189</td>\n",
       "      <td>63</td>\n",
       "      <td>1.781055</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>1.789996</td>\n",
       "      <td>0.271339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>378</td>\n",
       "      <td>126</td>\n",
       "      <td>1.781010</td>\n",
       "      <td>0.268545</td>\n",
       "      <td>1.790351</td>\n",
       "      <td>0.263404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hidden Layers  Epochs Count  Total Node Count  Train Data Node Count  \\\n",
       "0               0            20                21                     21   \n",
       "1               0            20                42                     42   \n",
       "2               0            20                63                     63   \n",
       "3               0            20               126                    126   \n",
       "4               0            40                21                     21   \n",
       "5               0            40                42                     42   \n",
       "6               0            40                63                     63   \n",
       "7               0            40               126                    126   \n",
       "8               0            60                21                     21   \n",
       "9               0            60                42                     42   \n",
       "10              0            60                63                     63   \n",
       "11              0            60               126                    126   \n",
       "12              1            20                42                     21   \n",
       "13              1            20                84                     42   \n",
       "14              1            20               126                     63   \n",
       "15              1            20               252                    126   \n",
       "16              1            40                42                     21   \n",
       "17              1            40                84                     42   \n",
       "18              1            40               126                     63   \n",
       "19              1            40               252                    126   \n",
       "20              1            60                42                     21   \n",
       "21              1            60                84                     42   \n",
       "22              1            60               126                     63   \n",
       "23              1            60               252                    126   \n",
       "24              2            20                63                     21   \n",
       "25              2            20               126                     42   \n",
       "26              2            20               189                     63   \n",
       "27              2            20               378                    126   \n",
       "28              2            40                63                     21   \n",
       "29              2            40               126                     42   \n",
       "30              2            40               189                     63   \n",
       "31              2            40               378                    126   \n",
       "32              2            60                63                     21   \n",
       "33              2            60               126                     42   \n",
       "34              2            60               189                     63   \n",
       "35              2            60               378                    126   \n",
       "\n",
       "    Train Data Loss  Train Data Accuracy  Test Data Loss  Test Data Accuracy  \n",
       "0          0.327741             0.863181        0.339329            0.858287  \n",
       "1          0.310537             0.870127        0.325061            0.861550  \n",
       "2          0.315582             0.865060        0.329314            0.857620  \n",
       "3          0.317246             0.865011        0.333143            0.860067  \n",
       "4          0.310974             0.869386        0.329700            0.858880  \n",
       "5          0.319334             0.867359        0.335841            0.858361  \n",
       "6          0.306415             0.869485        0.326561            0.859918  \n",
       "7          0.309974             0.869781        0.328521            0.861476  \n",
       "8          0.329852             0.859202        0.344219            0.852280  \n",
       "9          0.323259             0.863453        0.342327            0.855321  \n",
       "10         0.318611             0.867680        0.336418            0.860512  \n",
       "11         0.308642             0.866766        0.331533            0.859029  \n",
       "12         0.325362             0.864566        0.347562            0.853541  \n",
       "13         0.334937             0.862217        0.353863            0.853912  \n",
       "14         0.319909             0.863157        0.341393            0.855098  \n",
       "15         0.349731             0.855667        0.370522            0.850056  \n",
       "16         0.330174             0.866172        0.352376            0.854134  \n",
       "17         0.327437             0.860660        0.343453            0.852429  \n",
       "18         0.413216             0.836411        0.429758            0.829366  \n",
       "19         0.609251             0.729996        0.619357            0.726511  \n",
       "20         1.794847             0.264442        1.802839            0.264071  \n",
       "21         1.781028             0.268545        1.790515            0.263404  \n",
       "22         1.781043             0.272574        1.790223            0.271339  \n",
       "23         1.781670             0.272574        1.791153            0.271339  \n",
       "24         1.781791             0.268545        1.791253            0.263404  \n",
       "25         1.782314             0.268545        1.791726            0.263404  \n",
       "26         1.782036             0.272574        1.791667            0.271339  \n",
       "27         1.782851             0.272574        1.791234            0.271339  \n",
       "28         1.781232             0.272574        1.790403            0.271339  \n",
       "29         1.780899             0.268545        1.790250            0.263404  \n",
       "30         1.780996             0.268545        1.790213            0.263404  \n",
       "31         1.781228             0.268545        1.790610            0.263404  \n",
       "32         1.781045             0.268545        1.790362            0.263404  \n",
       "33         1.781215             0.268545        1.790910            0.263404  \n",
       "34         1.781055             0.272574        1.789996            0.271339  \n",
       "35         1.781010             0.268545        1.790351            0.263404  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model_dataframe = pd.DataFrame({\n",
    "    \"Hidden Layers\":hidden_layers,\n",
    "    \"Epochs Count\":train_data_epochs,\n",
    "    \"Total Node Count\":total_nodes,\n",
    "    \"Train Data Node Count\":train_data_node_count,\n",
    "    \"Train Data Loss\":train_data_loss,\n",
    "    \"Train Data Accuracy\":train_data_accuracy,\n",
    "    \"Test Data Loss\":test_data_loss,\n",
    "    \"Test Data Accuracy\":test_data_accuracy,\n",
    "    #\"Test Data Node Count\":test_data_node_count,\n",
    "    #\"Test Data Epochs Count\":test_data_epochs\n",
    "})\n",
    "trained_model_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_dataframe.to_csv(\"strat_trained_models_CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701273"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model_dataframe[\"Train Data Accuracy\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86154985"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model_dataframe[\"Test Data Accuracy\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.51832106,  0.        , -0.44719154],\n",
       "       [ 0.51832106,  1.        ,  0.        , -0.83245929],\n",
       "       [ 0.        ,  0.        ,  1.        , -0.27653679],\n",
       "       [-0.44719154, -0.83245929, -0.27653679,  1.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef([total_nodes, hidden_layers, train_data_epochs], y=train_data_accuracy, rowvar=True, bias=False, ddof=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.51832106,  0.        , -0.44591607],\n",
       "       [ 0.51832106,  1.        ,  0.        , -0.83344218],\n",
       "       [ 0.        ,  0.        ,  1.        , -0.2767044 ],\n",
       "       [-0.44591607, -0.83344218, -0.2767044 ,  1.        ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef([total_nodes, hidden_layers, train_data_epochs], y=test_data_accuracy, rowvar=True, bias=False, ddof=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.83344218],\n",
       "       [-0.83344218,  1.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(hidden_layers, y=test_data_accuracy, rowvar=True, bias=False, ddof=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create a normal neural network with 2 inputs, 6 hidden nodes, and 2 outputs\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=63, activation='relu', input_dim=21))\n",
    "model.add(Dense(units=63, activation='relu'))\n",
    "model.add(Dense(units=63, activation='relu'))\n",
    "model.add(Dense(units=9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_train_scaled, y_train_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
