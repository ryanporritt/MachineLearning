{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  carat      cut color clarity  depth  table  price     x     y  \\\n",
       "0           1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
       "1           2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
       "2           3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07   \n",
       "3           4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23   \n",
       "4           5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35   \n",
       "\n",
       "      z  \n",
       "0  2.43  \n",
       "1  2.31  \n",
       "2  2.31  \n",
       "3  2.63  \n",
       "4  2.75  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds = pd.read_csv('diamonds.csv')\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18823"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds[\"price\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds[\"price\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         326\n",
       "1         326\n",
       "2         327\n",
       "3         334\n",
       "4         335\n",
       "         ... \n",
       "53935    2757\n",
       "53936    2757\n",
       "53937    2757\n",
       "53938    2757\n",
       "53939    2757\n",
       "Name: price, Length: 53940, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bins for the Diamond Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins in which to place values based upon Diamond Price\n",
    "bins = [0, 499, 999, 2499, 4999, 7499, 9999, 14999, 19999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_groups = [1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for these bins\n",
    "group_labels = [\"0-500\", \"500-1000\", \"1000-2500\", \"2500-5000\", \"5000-7500\", \"7500-10000\", \"1000-15000\", \"15000-20000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  carat      cut color clarity  depth  table  price     x     y  \\\n",
       "0           1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
       "1           2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
       "2           3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07   \n",
       "3           4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23   \n",
       "4           5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35   \n",
       "\n",
       "      z bins  \n",
       "0  2.43    1  \n",
       "1  2.31    1  \n",
       "2  2.31    1  \n",
       "3  2.63    1  \n",
       "4  2.75    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice the data and place it into bins\n",
    "diamonds[\"bins\"] = pd.cut(diamonds[\"price\"], bins, labels=label_groups)\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53940, 4) (53940,)\n"
     ]
    }
   ],
   "source": [
    "X = diamonds[[\"carat\", \"cut\", \"color\", \"clarity\"]]\n",
    "y = diamonds[\"bins\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "53935    4\n",
       "53936    4\n",
       "53937    4\n",
       "53938    4\n",
       "53939    4\n",
       "Name: bins, Length: 53940, dtype: category\n",
       "Categories (8, int64): [1 < 2 < 3 < 4 < 5 < 6 < 7 < 8]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Encoding (Binary Encoded Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut_Fair</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>color_D</th>\n",
       "      <th>color_E</th>\n",
       "      <th>color_F</th>\n",
       "      <th>color_G</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_I1</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  cut_Fair  cut_Good  cut_Ideal  cut_Premium  cut_Very Good  color_D  \\\n",
       "0   0.23         0         0          1            0              0        0   \n",
       "1   0.21         0         0          0            1              0        0   \n",
       "2   0.23         0         1          0            0              0        0   \n",
       "3   0.29         0         0          0            1              0        0   \n",
       "4   0.31         0         1          0            0              0        0   \n",
       "\n",
       "   color_E  color_F  color_G  ...  color_I  color_J  clarity_I1  clarity_IF  \\\n",
       "0        1        0        0  ...        0        0           0           0   \n",
       "1        1        0        0  ...        0        0           0           0   \n",
       "2        1        0        0  ...        0        0           0           0   \n",
       "3        0        0        0  ...        1        0           0           0   \n",
       "4        0        0        0  ...        0        1           0           0   \n",
       "\n",
       "   clarity_SI1  clarity_SI2  clarity_VS1  clarity_VS2  clarity_VVS1  \\\n",
       "0            0            1            0            0             0   \n",
       "1            1            0            0            0             0   \n",
       "2            0            0            1            0             0   \n",
       "3            0            0            0            1             0   \n",
       "4            0            1            0            0             0   \n",
       "\n",
       "   clarity_VVS2  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = X.copy()\n",
    "\n",
    "data_binary_encoded = pd.get_dummies(data, columns=[\"cut\", \"color\", \"clarity\"])\n",
    "data_binary_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut_Fair</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>color_D</th>\n",
       "      <th>color_E</th>\n",
       "      <th>color_F</th>\n",
       "      <th>color_G</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_I1</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>35965</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52281</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6957</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9163</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50598</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  cut_Fair  cut_Good  cut_Ideal  cut_Premium  cut_Very Good  \\\n",
       "35965   0.25         0         1          0            0              0   \n",
       "52281   0.84         0         0          1            0              0   \n",
       "6957    1.05         0         0          0            1              0   \n",
       "9163    1.02         0         0          1            0              0   \n",
       "50598   0.61         0         0          1            0              0   \n",
       "\n",
       "       color_D  color_E  color_F  color_G  ...  color_I  color_J  clarity_I1  \\\n",
       "35965        0        1        0        0  ...        0        0           0   \n",
       "52281        0        0        0        0  ...        0        1           0   \n",
       "6957         0        0        0        0  ...        0        1           0   \n",
       "9163         0        0        1        0  ...        0        0           0   \n",
       "50598        0        0        1        0  ...        0        0           0   \n",
       "\n",
       "       clarity_IF  clarity_SI1  clarity_SI2  clarity_VS1  clarity_VS2  \\\n",
       "35965           0            0            0            0            0   \n",
       "52281           0            1            0            0            0   \n",
       "6957            0            0            0            0            1   \n",
       "9163            0            0            1            0            0   \n",
       "50598           0            0            0            1            0   \n",
       "\n",
       "       clarity_VVS1  clarity_VVS2  \n",
       "35965             0             1  \n",
       "52281             0             0  \n",
       "6957              0             0  \n",
       "9163              0             0  \n",
       "50598             0             0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_binary_encoded\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [21,42,63, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_count = [20,40,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_node_count = []\n",
    "train_data_accuracy = []\n",
    "train_data_loss = []\n",
    "train_data_epochs = []\n",
    "\n",
    "test_data_node_count = []\n",
    "test_data_accuracy = []\n",
    "test_data_loss = []\n",
    "test_data_epochs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Hidden Layers: \n",
      "\n",
      "Epochs count: 20 \n",
      "\n",
      "Model: 0\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 3s - loss: 0.3264 - acc: 0.8646\n",
      "Normal Neural Network - Loss: 0.32638762755706924, Train Data Accuracy: 0.8646396994590759  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3280 - acc: 0.8648\n",
      "Normal Neural Network - Loss: 0.3279775432051665, Test Data Accuracy: 0.8648127317428589 \n",
      "\n",
      "Model: 1\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 3s - loss: 0.3169 - acc: 0.8661\n",
      "Normal Neural Network - Loss: 0.31687921332187347, Train Data Accuracy: 0.8661475777626038  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3255 - acc: 0.8638\n",
      "Normal Neural Network - Loss: 0.32547561949078224, Test Data Accuracy: 0.8638487458229065 \n",
      "\n",
      "Model: 2\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 2s - loss: 0.3122 - acc: 0.8685\n",
      "Normal Neural Network - Loss: 0.31224977897560474, Train Data Accuracy: 0.8684958815574646  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3190 - acc: 0.8664\n",
      "Normal Neural Network - Loss: 0.318984039432259, Test Data Accuracy: 0.8663700222969055 \n",
      "\n",
      "Model: 3\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 3s - loss: 0.3193 - acc: 0.8629\n",
      "Normal Neural Network - Loss: 0.3193319055106168, Train Data Accuracy: 0.8629341125488281  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3284 - acc: 0.8641\n",
      "Normal Neural Network - Loss: 0.3284233139760856, Test Data Accuracy: 0.8641453385353088 \n",
      "\n",
      "Epochs count: 40 \n",
      "\n",
      "Model: 4\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 2s - loss: 0.3169 - acc: 0.8626\n",
      "Normal Neural Network - Loss: 0.31694140674790616, Train Data Accuracy: 0.8625633716583252  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3270 - acc: 0.8615\n",
      "Normal Neural Network - Loss: 0.32702030120047987, Test Data Accuracy: 0.8615498542785645 \n",
      "\n",
      "Model: 5\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 3s - loss: 0.3092 - acc: 0.8676\n",
      "Normal Neural Network - Loss: 0.30918416789665076, Train Data Accuracy: 0.8675812482833862  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3197 - acc: 0.8661\n",
      "Normal Neural Network - Loss: 0.31973137202685437, Test Data Accuracy: 0.8660734295845032 \n",
      "\n",
      "Model: 6\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 3s - loss: 0.3106 - acc: 0.8683\n",
      "Normal Neural Network - Loss: 0.3105929220544881, Train Data Accuracy: 0.8682981133460999  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3248 - acc: 0.8678\n",
      "Normal Neural Network - Loss: 0.3247508165568478, Test Data Accuracy: 0.867779016494751 \n",
      "\n",
      "Model: 7\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 3s - loss: 0.3102 - acc: 0.8683\n",
      "Normal Neural Network - Loss: 0.310247789906595, Train Data Accuracy: 0.8683475255966187  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3257 - acc: 0.8684\n",
      "Normal Neural Network - Loss: 0.3256604062304216, Test Data Accuracy: 0.868446409702301 \n",
      "\n",
      "Epochs count: 60 \n",
      "\n",
      "Model: 8\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 3s - loss: 0.3143 - acc: 0.8653\n",
      "Normal Neural Network - Loss: 0.3143123491543242, Train Data Accuracy: 0.8653071522712708  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3330 - acc: 0.8595\n",
      "Normal Neural Network - Loss: 0.332950400086213, Test Data Accuracy: 0.8595476746559143 \n",
      "\n",
      "Model: 9\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 3s - loss: 0.3323 - acc: 0.8594\n",
      "Normal Neural Network - Loss: 0.3322642105668249, Train Data Accuracy: 0.8593993186950684  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3432 - acc: 0.8578\n",
      "Normal Neural Network - Loss: 0.3432109690371115, Test Data Accuracy: 0.8577678799629211 \n",
      "\n",
      "Model: 10\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 4s - loss: 0.3210 - acc: 0.8685\n",
      "Normal Neural Network - Loss: 0.320961675899843, Train Data Accuracy: 0.8685205578804016  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3395 - acc: 0.8641\n",
      "Normal Neural Network - Loss: 0.3394853159039384, Test Data Accuracy: 0.8641453385353088 \n",
      "\n",
      "Model: 11\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 4s - loss: 0.4931 - acc: 0.8500\n",
      "Normal Neural Network - Loss: 0.49307033180704285, Train Data Accuracy: 0.8500061631202698  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.5330 - acc: 0.8455\n",
      "Normal Neural Network - Loss: 0.5329931833189773, Test Data Accuracy: 0.8455320596694946 \n",
      "\n",
      "One Hidden Layer: \n",
      "\n",
      "Epochs count: 20 \n",
      "\n",
      "Model: 12\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 4s - loss: 0.4449 - acc: 0.8249\n",
      "Normal Neural Network - Loss: 0.4448682196604986, Train Data Accuracy: 0.8248918652534485  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.4464 - acc: 0.8264\n",
      "Normal Neural Network - Loss: 0.446375084939956, Test Data Accuracy: 0.8263996839523315 \n",
      "\n",
      "Model: 13\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 4s - loss: 0.4976 - acc: 0.7989\n",
      "Normal Neural Network - Loss: 0.49764072974832313, Train Data Accuracy: 0.7988629341125488  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.5038 - acc: 0.7981\n",
      "Normal Neural Network - Loss: 0.5037969000656869, Test Data Accuracy: 0.7981460690498352 \n",
      "\n",
      "Model: 14\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 5s - loss: 0.3565 - acc: 0.8419\n",
      "Normal Neural Network - Loss: 0.3564974833272942, Train Data Accuracy: 0.8419478535652161  \n",
      "\n",
      "13485/13485 - 1s - loss: 0.3640 - acc: 0.8429\n",
      "Normal Neural Network - Loss: 0.36398571616064235, Test Data Accuracy: 0.8428624272346497 \n",
      "\n",
      "Model: 15\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 5s - loss: 0.5004 - acc: 0.7897\n",
      "Normal Neural Network - Loss: 0.5004219041215726, Train Data Accuracy: 0.7897416949272156  \n",
      "\n",
      "13485/13485 - 2s - loss: 0.4992 - acc: 0.7896\n",
      "Normal Neural Network - Loss: 0.49918112209606136, Test Data Accuracy: 0.7896180748939514 \n",
      "\n",
      "Epochs count: 40 \n",
      "\n",
      "Model: 16\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 5s - loss: 0.3389 - acc: 0.8628\n",
      "Normal Neural Network - Loss: 0.33888261037532336, Train Data Accuracy: 0.8628105521202087  \n",
      "\n",
      "13485/13485 - 2s - loss: 0.3489 - acc: 0.8604\n",
      "Normal Neural Network - Loss: 0.3489040634788581, Test Data Accuracy: 0.8603633642196655 \n",
      "\n",
      "Model: 17\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 6s - loss: 0.3538 - acc: 0.8446\n",
      "Normal Neural Network - Loss: 0.3538104200430197, Train Data Accuracy: 0.8445927500724792  \n",
      "\n",
      "13485/13485 - 2s - loss: 0.3638 - acc: 0.8461\n",
      "Normal Neural Network - Loss: 0.3637865602638618, Test Data Accuracy: 0.8461253046989441 \n",
      "\n",
      "Model: 18\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 6s - loss: 0.8435 - acc: 0.5982\n",
      "Normal Neural Network - Loss: 0.8435268622189631, Train Data Accuracy: 0.598170816898346  \n",
      "\n",
      "13485/13485 - 2s - loss: 0.8497 - acc: 0.5906\n",
      "Normal Neural Network - Loss: 0.849710601062124, Test Data Accuracy: 0.5905821323394775 \n",
      "\n",
      "Model: 19\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 6s - loss: 1.8320 - acc: 0.2437\n",
      "Normal Neural Network - Loss: 1.8319895689455927, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 2s - loss: 1.8268 - acc: 0.2360\n",
      "Normal Neural Network - Loss: 1.8268041317048318, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Epochs count: 60 \n",
      "\n",
      "Model: 20\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 8s - loss: 1.8319 - acc: 0.2437\n",
      "Normal Neural Network - Loss: 1.831906346460898, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 2s - loss: 1.8267 - acc: 0.2360\n",
      "Normal Neural Network - Loss: 1.8267153571082524, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Model: 21\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 7s - loss: 1.8319 - acc: 0.2437\n",
      "Normal Neural Network - Loss: 1.8318545534177286, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 2s - loss: 1.8265 - acc: 0.2360\n",
      "Normal Neural Network - Loss: 1.826545627381477, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Model: 22\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 8s - loss: 1.8323 - acc: 0.2353\n",
      "Normal Neural Network - Loss: 1.8322802179514766, Train Data Accuracy: 0.2353232055902481  \n",
      "\n",
      "13485/13485 - 2s - loss: 1.8262 - acc: 0.2410\n",
      "Normal Neural Network - Loss: 1.8262304564604372, Test Data Accuracy: 0.24100853502750397 \n",
      "\n",
      "Model: 23\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 8s - loss: 1.8320 - acc: 0.2437\n",
      "Normal Neural Network - Loss: 1.8320177968567048, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 3s - loss: 1.8271 - acc: 0.2360\n",
      "Normal Neural Network - Loss: 1.8271198802936683, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Two Hidden Layers: \n",
      "\n",
      "Epochs count: 20 \n",
      "\n",
      "Model: 24\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 16s - loss: 1.8324 - acc: 0.2353\n",
      "Deep Learning - Loss: 1.832375104102315, Train Data Accuracy: 0.2353232055902481  \n",
      "\n",
      "13485/13485 - 5s - loss: 1.8263 - acc: 0.2410\n",
      "Deep Learning - Loss: 1.8263489943236655, Test Data Accuracy: 0.24100853502750397 \n",
      "\n",
      "Model: 25\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 17s - loss: 1.8321 - acc: 0.2437\n",
      "Deep Learning - Loss: 1.8321261641976565, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 5s - loss: 1.8270 - acc: 0.2360\n",
      "Deep Learning - Loss: 1.8269844997534719, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Model: 26\n",
      "Number of Nodes: 63 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40455/40455 - 18s - loss: 1.8329 - acc: 0.2437\n",
      "Deep Learning - Loss: 1.8329056692954386, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 5s - loss: 1.8275 - acc: 0.2360\n",
      "Deep Learning - Loss: 1.8274736148143282, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Model: 27\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 19s - loss: 1.8326 - acc: 0.2437\n",
      "Deep Learning - Loss: 1.8325805363232532, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 5s - loss: 1.8277 - acc: 0.2360\n",
      "Deep Learning - Loss: 1.8276972956510664, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Epochs count: 40 \n",
      "\n",
      "Model: 28\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 20s - loss: 1.8320 - acc: 0.2437\n",
      "Deep Learning - Loss: 1.8320385142348632, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 6s - loss: 1.8263 - acc: 0.2360\n",
      "Deep Learning - Loss: 1.8262701239195143, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Model: 29\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 21s - loss: 1.8321 - acc: 0.2353\n",
      "Deep Learning - Loss: 1.832089532336616, Train Data Accuracy: 0.2353232055902481  \n",
      "\n",
      "13485/13485 - 6s - loss: 1.8264 - acc: 0.2410\n",
      "Deep Learning - Loss: 1.82635777277729, Test Data Accuracy: 0.24100853502750397 \n",
      "\n",
      "Model: 30\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 22s - loss: 1.8321 - acc: 0.2437\n",
      "Deep Learning - Loss: 1.8320831213491306, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 7s - loss: 1.8267 - acc: 0.2360\n",
      "Deep Learning - Loss: 1.8267180785188686, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Model: 31\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 24s - loss: 1.8320 - acc: 0.2437\n",
      "Deep Learning - Loss: 1.8320261195185983, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 7s - loss: 1.8270 - acc: 0.2360\n",
      "Deep Learning - Loss: 1.827012778318587, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Epochs count: 60 \n",
      "\n",
      "Model: 32\n",
      "Number of Nodes: 21 \n",
      "\n",
      "40455/40455 - 26s - loss: 1.8320 - acc: 0.2437\n",
      "Deep Learning - Loss: 1.8319670956857625, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 8s - loss: 1.8269 - acc: 0.2360\n",
      "Deep Learning - Loss: 1.8268577996209059, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Model: 33\n",
      "Number of Nodes: 42 \n",
      "\n",
      "40455/40455 - 27s - loss: 1.8320 - acc: 0.2437\n",
      "Deep Learning - Loss: 1.832040193434213, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 8s - loss: 1.8267 - acc: 0.2360\n",
      "Deep Learning - Loss: 1.8266934674803663, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Model: 34\n",
      "Number of Nodes: 63 \n",
      "\n",
      "40455/40455 - 28s - loss: 1.8321 - acc: 0.2437\n",
      "Deep Learning - Loss: 1.8320767065220778, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 8s - loss: 1.8270 - acc: 0.2360\n",
      "Deep Learning - Loss: 1.8269574710692482, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Model: 35\n",
      "Number of Nodes: 126 \n",
      "\n",
      "40455/40455 - 30s - loss: 1.8321 - acc: 0.2437\n",
      "Deep Learning - Loss: 1.83210375088871, Train Data Accuracy: 0.24367816746234894  \n",
      "\n",
      "13485/13485 - 9s - loss: 1.8264 - acc: 0.2360\n",
      "Deep Learning - Loss: 1.8263713490048028, Test Data Accuracy: 0.23604004085063934 \n",
      "\n",
      "Train Data Node Count: [21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63] \n",
      "\n",
      "Train Data Accuracy: [0.8646397, 0.8661476, 0.8684959, 0.8629341, 0.8625634, 0.86758125, 0.8682981, 0.8683475, 0.86530715, 0.8593993, 0.86852056, 0.85000616, 0.82489187, 0.79886293, 0.84194785, 0.7897417, 0.86281055, 0.84459275, 0.5981708, 0.24367817, 0.24367817, 0.24367817, 0.2353232, 0.24367817, 0.2353232, 0.24367817, 0.24367817, 0.24367817, 0.24367817, 0.2353232, 0.24367817, 0.24367817, 0.24367817, 0.24367817, 0.24367817, 0.24367817] \n",
      "\n",
      "Train Data Data Loss: [0.32638762755706924, 0.31687921332187347, 0.31224977897560474, 0.3193319055106168, 0.31694140674790616, 0.30918416789665076, 0.3105929220544881, 0.310247789906595, 0.3143123491543242, 0.3322642105668249, 0.320961675899843, 0.49307033180704285, 0.4448682196604986, 0.49764072974832313, 0.3564974833272942, 0.5004219041215726, 0.33888261037532336, 0.3538104200430197, 0.8435268622189631, 1.8319895689455927, 1.831906346460898, 1.8318545534177286, 1.8322802179514766, 1.8320177968567048, 1.832375104102315, 1.8321261641976565, 1.8329056692954386, 1.8325805363232532, 1.8320385142348632, 1.832089532336616, 1.8320831213491306, 1.8320261195185983, 1.8319670956857625, 1.832040193434213, 1.8320767065220778, 1.83210375088871] \n",
      "\n",
      "Train Data Epochs Count: [20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60] \n",
      "\n",
      "Test Data Node Count: [21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63] \n",
      "\n",
      "Test Data Accuracy: [0.86481273, 0.86384875, 0.86637, 0.86414534, 0.86154985, 0.8660734, 0.867779, 0.8684464, 0.8595477, 0.8577679, 0.86414534, 0.84553206, 0.8263997, 0.79814607, 0.8428624, 0.7896181, 0.86036336, 0.8461253, 0.59058213, 0.23604004, 0.23604004, 0.23604004, 0.24100854, 0.23604004, 0.24100854, 0.23604004, 0.23604004, 0.23604004, 0.23604004, 0.24100854, 0.23604004, 0.23604004, 0.23604004, 0.23604004, 0.23604004, 0.23604004] \n",
      "\n",
      "Test Data Data Loss: [0.3279775432051665, 0.32547561949078224, 0.318984039432259, 0.3284233139760856, 0.32702030120047987, 0.31973137202685437, 0.3247508165568478, 0.3256604062304216, 0.332950400086213, 0.3432109690371115, 0.3394853159039384, 0.5329931833189773, 0.446375084939956, 0.5037969000656869, 0.36398571616064235, 0.49918112209606136, 0.3489040634788581, 0.3637865602638618, 0.849710601062124, 1.8268041317048318, 1.8267153571082524, 1.826545627381477, 1.8262304564604372, 1.8271198802936683, 1.8263489943236655, 1.8269844997534719, 1.8274736148143282, 1.8276972956510664, 1.8262701239195143, 1.82635777277729, 1.8267180785188686, 1.827012778318587, 1.8268577996209059, 1.8266934674803663, 1.8269574710692482, 1.8263713490048028] \n",
      "\n",
      "Test Data Epochs Count: [20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "\n",
    "k = 0\n",
    "\n",
    "for i in range(3):\n",
    "    count = nodes[i]\n",
    "    \n",
    "    if i == 0:\n",
    "        print(\"No Hidden Layers: \\n\")\n",
    "        for j in range(3):\n",
    "            current_epochs_count = epochs_count[j]\n",
    "\n",
    "            print(f\"Epochs count: {current_epochs_count} \\n\")\n",
    "            for i in range(len(nodes)):\n",
    "                print(f\"Model: {k}\")\n",
    "                #create 4 models with varying node sizes 21,42,63,126\n",
    "                model.add(Dense(units=count, activation='relu', input_dim=21))\n",
    "                model.add(Dense(units=9, activation='softmax'))\n",
    "                #print(model.summary())\n",
    "\n",
    "                # Compile the model\n",
    "                model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "                # Fit the model to the training data\n",
    "                model.fit(\n",
    "                    X_train_scaled,\n",
    "                    y_train_categorical,\n",
    "                    epochs=current_epochs_count,\n",
    "                    shuffle=True,\n",
    "                    verbose=0\n",
    "                )\n",
    "\n",
    "                # Print the number of nodes for this model\n",
    "                print(f\"Number of Nodes: {nodes[i]} \\n\")\n",
    "\n",
    "                # Print the training data accuracy\n",
    "                model_loss, model_accuracy = model.evaluate(X_train_scaled, y_train_categorical, verbose=2)\n",
    "                print(f\"Normal Neural Network - Loss: {model_loss}, Train Data Accuracy: {model_accuracy}  \\n\")\n",
    "\n",
    "                # Append aquired data to lists\n",
    "                train_data_node_count.append(nodes[i])\n",
    "                train_data_accuracy.append(model_accuracy)\n",
    "                train_data_loss.append(model_loss)\n",
    "                train_data_epochs.append(current_epochs_count)\n",
    "\n",
    "                # Print the test data accuracy\n",
    "                model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "                print(f\"Normal Neural Network - Loss: {model_loss}, Test Data Accuracy: {model_accuracy} \\n\")\n",
    "\n",
    "                # Append aquired data to lists\n",
    "                test_data_node_count.append(nodes[i])\n",
    "                test_data_accuracy.append(model_accuracy)\n",
    "                test_data_loss.append(model_loss)\n",
    "                test_data_epochs.append(current_epochs_count)\n",
    "                \n",
    "                # Save the Model\n",
    "                model.save(f\"Models/diamond_model{k}_trained.h5\")\n",
    "                k += 1\n",
    "            \n",
    "            \n",
    "    if i == 1:\n",
    "        print(\"One Hidden Layer: \\n\")\n",
    "        for j in range(3):\n",
    "            current_epochs_count = epochs_count[j]\n",
    "\n",
    "            print(f\"Epochs count: {current_epochs_count} \\n\")\n",
    "            for i in range(len(nodes)):\n",
    "                print(f\"Model: {k}\")\n",
    "                model.add(Dense(units=count, activation='relu', input_dim=21))\n",
    "                model.add(Dense(units=count, activation='relu'))\n",
    "                model.add(Dense(units=9, activation='softmax'))\n",
    "                #print(model.summary())\n",
    "\n",
    "                # Compile the model\n",
    "                model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "                # Fit the model to the training data\n",
    "                model.fit(\n",
    "                    X_train_scaled,\n",
    "                    y_train_categorical,\n",
    "                    epochs=current_epochs_count,\n",
    "                    shuffle=True,\n",
    "                    verbose=0\n",
    "                )\n",
    "\n",
    "                # Print the number of nodes for this model\n",
    "                print(f\"Number of Nodes: {nodes[i]} \\n\")\n",
    "\n",
    "                # Print the training data accuracy\n",
    "                model_loss, model_accuracy = model.evaluate(X_train_scaled, y_train_categorical, verbose=2)\n",
    "                print(f\"Normal Neural Network - Loss: {model_loss}, Train Data Accuracy: {model_accuracy}  \\n\")\n",
    "\n",
    "                # Append aquired data to lists\n",
    "                train_data_node_count.append(nodes[i])\n",
    "                train_data_accuracy.append(model_accuracy)\n",
    "                train_data_loss.append(model_loss)\n",
    "                train_data_epochs.append(current_epochs_count)\n",
    "\n",
    "                # Print the test data accuracy\n",
    "                model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "                print(f\"Normal Neural Network - Loss: {model_loss}, Test Data Accuracy: {model_accuracy} \\n\")\n",
    "\n",
    "                # Append aquired data to lists\n",
    "                test_data_node_count.append(nodes[i])\n",
    "                test_data_accuracy.append(model_accuracy)\n",
    "                test_data_loss.append(model_loss)\n",
    "                test_data_epochs.append(current_epochs_count)\n",
    "                \n",
    "                # Save the Model\n",
    "                model.save(f\"Models/diamond_model{k}_trained.h5\")\n",
    "                k += 1\n",
    "    \n",
    "    if i == 2:\n",
    "        print(\"Two Hidden Layers: \\n\")\n",
    "        for j in range(3):\n",
    "            current_epochs_count = epochs_count[j]\n",
    "\n",
    "            print(f\"Epochs count: {current_epochs_count} \\n\")\n",
    "            for i in range(len(nodes)):\n",
    "                print(f\"Model: {k}\")\n",
    "\n",
    "                model.add(Dense(units=count, activation='relu', input_dim=21))\n",
    "                model.add(Dense(units=count, activation='relu'))\n",
    "                model.add(Dense(units=count, activation='relu'))\n",
    "                model.add(Dense(units=9, activation='softmax'))\n",
    "                #print(model.summary())\n",
    "\n",
    "                # Compile the model\n",
    "                model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "                # Fit the model to the training data\n",
    "                model.fit(\n",
    "                    X_train_scaled,\n",
    "                    y_train_categorical,\n",
    "                    epochs=current_epochs_count,\n",
    "                    shuffle=True,\n",
    "                    verbose=0\n",
    "                )\n",
    "\n",
    "                # Print the number of nodes for this model\n",
    "                print(f\"Number of Nodes: {nodes[i]} \\n\")\n",
    "\n",
    "                # Print the training data accuracy\n",
    "                model_loss, model_accuracy = model.evaluate(X_train_scaled, y_train_categorical, verbose=2)\n",
    "                print(f\"Deep Learning - Loss: {model_loss}, Train Data Accuracy: {model_accuracy}  \\n\")\n",
    "\n",
    "                # Append aquired data to lists\n",
    "                train_data_node_count.append(nodes[i])\n",
    "                train_data_accuracy.append(model_accuracy)\n",
    "                train_data_loss.append(model_loss)\n",
    "                train_data_epochs.append(current_epochs_count)\n",
    "\n",
    "                # Print the test data accuracy\n",
    "                model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "                print(f\"Deep Learning - Loss: {model_loss}, Test Data Accuracy: {model_accuracy} \\n\")\n",
    "\n",
    "                # Append aquired data to lists\n",
    "                test_data_node_count.append(nodes[i])\n",
    "                test_data_accuracy.append(model_accuracy)\n",
    "                test_data_loss.append(model_loss)\n",
    "                test_data_epochs.append(current_epochs_count)\n",
    "                \n",
    "                # Save the Model\n",
    "                model.save(f\"Models/diamond_model{k}_trained.h5\")\n",
    "                k += 1\n",
    "                \n",
    "# Print the lists\n",
    "print(f\"Train Data Node Count: {train_data_node_count} \\n\")\n",
    "print(f\"Train Data Accuracy: {train_data_accuracy} \\n\")\n",
    "print(f\"Train Data Data Loss: {train_data_loss} \\n\")\n",
    "print(f\"Train Data Epochs Count: {train_data_epochs} \\n\")\n",
    "\n",
    "print(f\"Test Data Node Count: {test_data_node_count} \\n\")\n",
    "print(f\"Test Data Accuracy: {test_data_accuracy} \\n\")\n",
    "print(f\"Test Data Data Loss: {test_data_loss} \\n\")\n",
    "print(f\"Test Data Epochs Count: {test_data_epochs} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Node Count: [21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126] \n",
      "\n",
      "Train Data Accuracy: [0.8646397, 0.8661476, 0.8684959, 0.8629341, 0.8625634, 0.86758125, 0.8682981, 0.8683475, 0.86530715, 0.8593993, 0.86852056, 0.85000616, 0.82489187, 0.79886293, 0.84194785, 0.7897417, 0.86281055, 0.84459275, 0.5981708, 0.24367817, 0.24367817, 0.24367817, 0.2353232, 0.24367817, 0.2353232, 0.24367817, 0.24367817, 0.24367817, 0.24367817, 0.2353232, 0.24367817, 0.24367817, 0.24367817, 0.24367817, 0.24367817, 0.24367817] \n",
      "\n",
      "Train Data Data Loss: [0.32638762755706924, 0.31687921332187347, 0.31224977897560474, 0.3193319055106168, 0.31694140674790616, 0.30918416789665076, 0.3105929220544881, 0.310247789906595, 0.3143123491543242, 0.3322642105668249, 0.320961675899843, 0.49307033180704285, 0.4448682196604986, 0.49764072974832313, 0.3564974833272942, 0.5004219041215726, 0.33888261037532336, 0.3538104200430197, 0.8435268622189631, 1.8319895689455927, 1.831906346460898, 1.8318545534177286, 1.8322802179514766, 1.8320177968567048, 1.832375104102315, 1.8321261641976565, 1.8329056692954386, 1.8325805363232532, 1.8320385142348632, 1.832089532336616, 1.8320831213491306, 1.8320261195185983, 1.8319670956857625, 1.832040193434213, 1.8320767065220778, 1.83210375088871] \n",
      "\n",
      "Train Data Epochs Count: [20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60] \n",
      "\n",
      "Test Data Node Count: [21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126] \n",
      "\n",
      "Test Data Accuracy: [0.86481273, 0.86384875, 0.86637, 0.86414534, 0.86154985, 0.8660734, 0.867779, 0.8684464, 0.8595477, 0.8577679, 0.86414534, 0.84553206, 0.8263997, 0.79814607, 0.8428624, 0.7896181, 0.86036336, 0.8461253, 0.59058213, 0.23604004, 0.23604004, 0.23604004, 0.24100854, 0.23604004, 0.24100854, 0.23604004, 0.23604004, 0.23604004, 0.23604004, 0.24100854, 0.23604004, 0.23604004, 0.23604004, 0.23604004, 0.23604004, 0.23604004] \n",
      "\n",
      "Test Data Data Loss: [0.3279775432051665, 0.32547561949078224, 0.318984039432259, 0.3284233139760856, 0.32702030120047987, 0.31973137202685437, 0.3247508165568478, 0.3256604062304216, 0.332950400086213, 0.3432109690371115, 0.3394853159039384, 0.5329931833189773, 0.446375084939956, 0.5037969000656869, 0.36398571616064235, 0.49918112209606136, 0.3489040634788581, 0.3637865602638618, 0.849710601062124, 1.8268041317048318, 1.8267153571082524, 1.826545627381477, 1.8262304564604372, 1.8271198802936683, 1.8263489943236655, 1.8269844997534719, 1.8274736148143282, 1.8276972956510664, 1.8262701239195143, 1.82635777277729, 1.8267180785188686, 1.827012778318587, 1.8268577996209059, 1.8266934674803663, 1.8269574710692482, 1.8263713490048028] \n",
      "\n",
      "Test Data Epochs Count: [20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the lists\n",
    "print(f\"Train Data Node Count: {train_data_node_count} \\n\")\n",
    "print(f\"Train Data Accuracy: {train_data_accuracy} \\n\")\n",
    "print(f\"Train Data Data Loss: {train_data_loss} \\n\")\n",
    "print(f\"Train Data Epochs Count: {train_data_epochs} \\n\")\n",
    "print(f\"Test Data Node Count: {test_data_node_count} \\n\")\n",
    "print(f\"Test Data Accuracy: {test_data_accuracy} \\n\")\n",
    "print(f\"Test Data Data Loss: {test_data_loss} \\n\")\n",
    "print(f\"Test Data Epochs Count: {test_data_epochs} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nodes = [21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 42, 84, 126, 252, 42, 84, 126, 252, 42, 84, 126, 252,63, 126, 189, 378, 63, 126, 189, 378, 63, 126, 189, 378]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_node_count = [21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126] \n",
    "\n",
    "train_data_accuracy = [0.8646397, 0.8661476, 0.8684959, 0.8629341, 0.8625634, 0.86758125, 0.8682981, 0.8683475, 0.86530715, 0.8593993, 0.86852056, 0.85000616, 0.82489187, 0.79886293, 0.84194785, 0.7897417, 0.86281055, 0.84459275, 0.5981708, 0.24367817, 0.24367817, 0.24367817, 0.2353232, 0.24367817, 0.2353232, 0.24367817, 0.24367817, 0.24367817, 0.24367817, 0.2353232, 0.24367817, 0.24367817, 0.24367817, 0.24367817, 0.24367817, 0.24367817] \n",
    "\n",
    "train_data_loss = [0.32638762755706924, 0.31687921332187347, 0.31224977897560474, 0.3193319055106168, 0.31694140674790616, 0.30918416789665076, 0.3105929220544881, 0.310247789906595, 0.3143123491543242, 0.3322642105668249, 0.320961675899843, 0.49307033180704285, 0.4448682196604986, 0.49764072974832313, 0.3564974833272942, 0.5004219041215726, 0.33888261037532336, 0.3538104200430197, 0.8435268622189631, 1.8319895689455927, 1.831906346460898, 1.8318545534177286, 1.8322802179514766, 1.8320177968567048, 1.832375104102315, 1.8321261641976565, 1.8329056692954386, 1.8325805363232532, 1.8320385142348632, 1.832089532336616, 1.8320831213491306, 1.8320261195185983, 1.8319670956857625, 1.832040193434213, 1.8320767065220778, 1.83210375088871] \n",
    "\n",
    "train_data_epochs = [20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60] \n",
    "\n",
    "test_data_node_count = [21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126, 21, 42, 63, 126] \n",
    "\n",
    "test_data_accuracy = [0.86481273, 0.86384875, 0.86637, 0.86414534, 0.86154985, 0.8660734, 0.867779, 0.8684464, 0.8595477, 0.8577679, 0.86414534, 0.84553206, 0.8263997, 0.79814607, 0.8428624, 0.7896181, 0.86036336, 0.8461253, 0.59058213, 0.23604004, 0.23604004, 0.23604004, 0.24100854, 0.23604004, 0.24100854, 0.23604004, 0.23604004, 0.23604004, 0.23604004, 0.24100854, 0.23604004, 0.23604004, 0.23604004, 0.23604004, 0.23604004, 0.23604004] \n",
    "\n",
    "test_data_loss = [0.3279775432051665, 0.32547561949078224, 0.318984039432259, 0.3284233139760856, 0.32702030120047987, 0.31973137202685437, 0.3247508165568478, 0.3256604062304216, 0.332950400086213, 0.3432109690371115, 0.3394853159039384, 0.5329931833189773, 0.446375084939956, 0.5037969000656869, 0.36398571616064235, 0.49918112209606136, 0.3489040634788581, 0.3637865602638618, 0.849710601062124, 1.8268041317048318, 1.8267153571082524, 1.826545627381477, 1.8262304564604372, 1.8271198802936683, 1.8263489943236655, 1.8269844997534719, 1.8274736148143282, 1.8276972956510664, 1.8262701239195143, 1.82635777277729, 1.8267180785188686, 1.827012778318587, 1.8268577996209059, 1.8266934674803663, 1.8269574710692482, 1.8263713490048028] \n",
    "\n",
    "test_data_epochs = [20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60, 20, 20, 20, 20, 40, 40, 40, 40, 60, 60, 60, 60] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Epochs Count</th>\n",
       "      <th>Total Node Count</th>\n",
       "      <th>Train Data Node Count</th>\n",
       "      <th>Train Data Loss</th>\n",
       "      <th>Train Data Accuracy</th>\n",
       "      <th>Test Data Loss</th>\n",
       "      <th>Test Data Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0.326388</td>\n",
       "      <td>0.864640</td>\n",
       "      <td>0.327978</td>\n",
       "      <td>0.864813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.316879</td>\n",
       "      <td>0.866148</td>\n",
       "      <td>0.325476</td>\n",
       "      <td>0.863849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.312250</td>\n",
       "      <td>0.868496</td>\n",
       "      <td>0.318984</td>\n",
       "      <td>0.866370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>0.319332</td>\n",
       "      <td>0.862934</td>\n",
       "      <td>0.328423</td>\n",
       "      <td>0.864145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0.316941</td>\n",
       "      <td>0.862563</td>\n",
       "      <td>0.327020</td>\n",
       "      <td>0.861550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.309184</td>\n",
       "      <td>0.867581</td>\n",
       "      <td>0.319731</td>\n",
       "      <td>0.866073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.310593</td>\n",
       "      <td>0.868298</td>\n",
       "      <td>0.324751</td>\n",
       "      <td>0.867779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>0.310248</td>\n",
       "      <td>0.868348</td>\n",
       "      <td>0.325660</td>\n",
       "      <td>0.868446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0.314312</td>\n",
       "      <td>0.865307</td>\n",
       "      <td>0.332950</td>\n",
       "      <td>0.859548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.332264</td>\n",
       "      <td>0.859399</td>\n",
       "      <td>0.343211</td>\n",
       "      <td>0.857768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.320962</td>\n",
       "      <td>0.868521</td>\n",
       "      <td>0.339485</td>\n",
       "      <td>0.864145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>0.493070</td>\n",
       "      <td>0.850006</td>\n",
       "      <td>0.532993</td>\n",
       "      <td>0.845532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>0.444868</td>\n",
       "      <td>0.824892</td>\n",
       "      <td>0.446375</td>\n",
       "      <td>0.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "      <td>0.497641</td>\n",
       "      <td>0.798863</td>\n",
       "      <td>0.503797</td>\n",
       "      <td>0.798146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>126</td>\n",
       "      <td>63</td>\n",
       "      <td>0.356497</td>\n",
       "      <td>0.841948</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.842862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>252</td>\n",
       "      <td>126</td>\n",
       "      <td>0.500422</td>\n",
       "      <td>0.789742</td>\n",
       "      <td>0.499181</td>\n",
       "      <td>0.789618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>0.338883</td>\n",
       "      <td>0.862811</td>\n",
       "      <td>0.348904</td>\n",
       "      <td>0.860363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "      <td>0.353810</td>\n",
       "      <td>0.844593</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.846125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>126</td>\n",
       "      <td>63</td>\n",
       "      <td>0.843527</td>\n",
       "      <td>0.598171</td>\n",
       "      <td>0.849711</td>\n",
       "      <td>0.590582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>252</td>\n",
       "      <td>126</td>\n",
       "      <td>1.831990</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.826804</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>1.831906</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.826715</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "      <td>1.831855</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.826546</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>126</td>\n",
       "      <td>63</td>\n",
       "      <td>1.832280</td>\n",
       "      <td>0.235323</td>\n",
       "      <td>1.826230</td>\n",
       "      <td>0.241009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>252</td>\n",
       "      <td>126</td>\n",
       "      <td>1.832018</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.827120</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>21</td>\n",
       "      <td>1.832375</td>\n",
       "      <td>0.235323</td>\n",
       "      <td>1.826349</td>\n",
       "      <td>0.241009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>1.832126</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.826984</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>189</td>\n",
       "      <td>63</td>\n",
       "      <td>1.832906</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.827474</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>378</td>\n",
       "      <td>126</td>\n",
       "      <td>1.832581</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.827697</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>21</td>\n",
       "      <td>1.832039</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.826270</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>1.832090</td>\n",
       "      <td>0.235323</td>\n",
       "      <td>1.826358</td>\n",
       "      <td>0.241009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>189</td>\n",
       "      <td>63</td>\n",
       "      <td>1.832083</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.826718</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>378</td>\n",
       "      <td>126</td>\n",
       "      <td>1.832026</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.827013</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>21</td>\n",
       "      <td>1.831967</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.826858</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>1.832040</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.826693</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>189</td>\n",
       "      <td>63</td>\n",
       "      <td>1.832077</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.826957</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>378</td>\n",
       "      <td>126</td>\n",
       "      <td>1.832104</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>1.826371</td>\n",
       "      <td>0.236040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hidden Layers  Epochs Count  Total Node Count  Train Data Node Count  \\\n",
       "0               0            20                21                     21   \n",
       "1               0            20                42                     42   \n",
       "2               0            20                63                     63   \n",
       "3               0            20               126                    126   \n",
       "4               0            40                21                     21   \n",
       "5               0            40                42                     42   \n",
       "6               0            40                63                     63   \n",
       "7               0            40               126                    126   \n",
       "8               0            60                21                     21   \n",
       "9               0            60                42                     42   \n",
       "10              0            60                63                     63   \n",
       "11              0            60               126                    126   \n",
       "12              1            20                42                     21   \n",
       "13              1            20                84                     42   \n",
       "14              1            20               126                     63   \n",
       "15              1            20               252                    126   \n",
       "16              1            40                42                     21   \n",
       "17              1            40                84                     42   \n",
       "18              1            40               126                     63   \n",
       "19              1            40               252                    126   \n",
       "20              1            60                42                     21   \n",
       "21              1            60                84                     42   \n",
       "22              1            60               126                     63   \n",
       "23              1            60               252                    126   \n",
       "24              2            20                63                     21   \n",
       "25              2            20               126                     42   \n",
       "26              2            20               189                     63   \n",
       "27              2            20               378                    126   \n",
       "28              2            40                63                     21   \n",
       "29              2            40               126                     42   \n",
       "30              2            40               189                     63   \n",
       "31              2            40               378                    126   \n",
       "32              2            60                63                     21   \n",
       "33              2            60               126                     42   \n",
       "34              2            60               189                     63   \n",
       "35              2            60               378                    126   \n",
       "\n",
       "    Train Data Loss  Train Data Accuracy  Test Data Loss  Test Data Accuracy  \n",
       "0          0.326388             0.864640        0.327978            0.864813  \n",
       "1          0.316879             0.866148        0.325476            0.863849  \n",
       "2          0.312250             0.868496        0.318984            0.866370  \n",
       "3          0.319332             0.862934        0.328423            0.864145  \n",
       "4          0.316941             0.862563        0.327020            0.861550  \n",
       "5          0.309184             0.867581        0.319731            0.866073  \n",
       "6          0.310593             0.868298        0.324751            0.867779  \n",
       "7          0.310248             0.868348        0.325660            0.868446  \n",
       "8          0.314312             0.865307        0.332950            0.859548  \n",
       "9          0.332264             0.859399        0.343211            0.857768  \n",
       "10         0.320962             0.868521        0.339485            0.864145  \n",
       "11         0.493070             0.850006        0.532993            0.845532  \n",
       "12         0.444868             0.824892        0.446375            0.826400  \n",
       "13         0.497641             0.798863        0.503797            0.798146  \n",
       "14         0.356497             0.841948        0.363986            0.842862  \n",
       "15         0.500422             0.789742        0.499181            0.789618  \n",
       "16         0.338883             0.862811        0.348904            0.860363  \n",
       "17         0.353810             0.844593        0.363787            0.846125  \n",
       "18         0.843527             0.598171        0.849711            0.590582  \n",
       "19         1.831990             0.243678        1.826804            0.236040  \n",
       "20         1.831906             0.243678        1.826715            0.236040  \n",
       "21         1.831855             0.243678        1.826546            0.236040  \n",
       "22         1.832280             0.235323        1.826230            0.241009  \n",
       "23         1.832018             0.243678        1.827120            0.236040  \n",
       "24         1.832375             0.235323        1.826349            0.241009  \n",
       "25         1.832126             0.243678        1.826984            0.236040  \n",
       "26         1.832906             0.243678        1.827474            0.236040  \n",
       "27         1.832581             0.243678        1.827697            0.236040  \n",
       "28         1.832039             0.243678        1.826270            0.236040  \n",
       "29         1.832090             0.235323        1.826358            0.241009  \n",
       "30         1.832083             0.243678        1.826718            0.236040  \n",
       "31         1.832026             0.243678        1.827013            0.236040  \n",
       "32         1.831967             0.243678        1.826858            0.236040  \n",
       "33         1.832040             0.243678        1.826693            0.236040  \n",
       "34         1.832077             0.243678        1.826957            0.236040  \n",
       "35         1.832104             0.243678        1.826371            0.236040  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model_dataframe = pd.DataFrame({\n",
    "    \"Hidden Layers\":hidden_layers,\n",
    "    \"Epochs Count\":train_data_epochs,\n",
    "    \"Total Node Count\":total_nodes,\n",
    "    \"Train Data Node Count\":train_data_node_count,\n",
    "    \"Train Data Loss\":train_data_loss,\n",
    "    \"Train Data Accuracy\":train_data_accuracy,\n",
    "    \"Test Data Loss\":test_data_loss,\n",
    "    \"Test Data Accuracy\":test_data_accuracy\n",
    "    #\"Test Data Node Count\":test_data_node_count,\n",
    "    #\"Test Data Epochs Count\":test_data_epochs\n",
    "})\n",
    "trained_model_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_dataframe.to_csv(\"trained_models_CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'Resources\\trained_models.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0d6ad9450dcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrained_model_dataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Resources\\trained_models.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonWebMongo\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index)\u001b[0m\n\u001b[0;32m   2422\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2423\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2424\u001b[1;33m             \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2425\u001b[0m         )\n\u001b[0;32m   2426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonWebMongo\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonWebMongo\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'Resources\\trained_models.json'"
     ]
    }
   ],
   "source": [
    "trained_model_dataframe.to_json(r\"Resources\\trained_models.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.51832106,  0.        , -0.5113981 ],\n",
       "       [ 0.51832106,  1.        ,  0.        , -0.84363156],\n",
       "       [ 0.        ,  0.        ,  1.        , -0.25990108],\n",
       "       [-0.5113981 , -0.84363156, -0.25990108,  1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef([total_nodes, hidden_layers, train_data_epochs], y=train_data_accuracy, rowvar=True, bias=False, ddof=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.51832106,  0.        , -0.51357789],\n",
       "       [ 0.51832106,  1.        ,  0.        , -0.84295684],\n",
       "       [ 0.        ,  0.        ,  1.        , -0.26330327],\n",
       "       [-0.51357789, -0.84295684, -0.26330327,  1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef([total_nodes, hidden_layers, train_data_epochs], y=test_data_accuracy, rowvar=True, bias=False, ddof=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.84295684],\n",
       "       [-0.84295684,  1.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(hidden_layers, y=test_data_accuracy, rowvar=True, bias=False, ddof=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ryanj\\Anaconda3\\envs\\PythonWebMongo\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# first, create a normal neural network with 2 inputs, 6 hidden nodes, and 2 outputs\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=63, activation='relu', input_dim=21))\n",
    "model.add(Dense(units=63, activation='relu'))\n",
    "model.add(Dense(units=63, activation='relu'))\n",
    "model.add(Dense(units=9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 63)                1386      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 576       \n",
      "=================================================================\n",
      "Total params: 1,962\n",
      "Trainable params: 1,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40455/40455 - 1s - loss: 1.1088 - acc: 0.5845\n",
      "Epoch 2/100\n",
      "40455/40455 - 1s - loss: 0.5830 - acc: 0.7998\n",
      "Epoch 3/100\n",
      "40455/40455 - 1s - loss: 0.4526 - acc: 0.8285\n",
      "Epoch 4/100\n",
      "40455/40455 - 1s - loss: 0.4005 - acc: 0.8401\n",
      "Epoch 5/100\n",
      "40455/40455 - 1s - loss: 0.3745 - acc: 0.8492\n",
      "Epoch 6/100\n",
      "40455/40455 - 1s - loss: 0.3598 - acc: 0.8534\n",
      "Epoch 7/100\n",
      "40455/40455 - 1s - loss: 0.3495 - acc: 0.8560\n",
      "Epoch 8/100\n",
      "40455/40455 - 1s - loss: 0.3435 - acc: 0.8573\n",
      "Epoch 9/100\n",
      "40455/40455 - 1s - loss: 0.3378 - acc: 0.8584\n",
      "Epoch 10/100\n",
      "40455/40455 - 1s - loss: 0.3350 - acc: 0.8596\n",
      "Epoch 11/100\n",
      "40455/40455 - 1s - loss: 0.3319 - acc: 0.8620\n",
      "Epoch 12/100\n",
      "40455/40455 - 1s - loss: 0.3295 - acc: 0.8624\n",
      "Epoch 13/100\n",
      "40455/40455 - 1s - loss: 0.3281 - acc: 0.8628\n",
      "Epoch 14/100\n",
      "40455/40455 - 1s - loss: 0.3254 - acc: 0.8628\n",
      "Epoch 15/100\n",
      "40455/40455 - 1s - loss: 0.3252 - acc: 0.8622\n",
      "Epoch 16/100\n",
      "40455/40455 - 1s - loss: 0.3238 - acc: 0.8640\n",
      "Epoch 17/100\n",
      "40455/40455 - 1s - loss: 0.3227 - acc: 0.8637\n",
      "Epoch 18/100\n",
      "40455/40455 - 1s - loss: 0.3211 - acc: 0.8643\n",
      "Epoch 19/100\n",
      "40455/40455 - 1s - loss: 0.3212 - acc: 0.8637\n",
      "Epoch 20/100\n",
      "40455/40455 - 1s - loss: 0.3206 - acc: 0.8638\n",
      "Epoch 21/100\n",
      "40455/40455 - 1s - loss: 0.3197 - acc: 0.8656\n",
      "Epoch 22/100\n",
      "40455/40455 - 1s - loss: 0.3192 - acc: 0.8647\n",
      "Epoch 23/100\n",
      "40455/40455 - 1s - loss: 0.3180 - acc: 0.8643\n",
      "Epoch 24/100\n",
      "40455/40455 - 1s - loss: 0.3176 - acc: 0.8659\n",
      "Epoch 25/100\n",
      "40455/40455 - 1s - loss: 0.3180 - acc: 0.8648\n",
      "Epoch 26/100\n",
      "40455/40455 - 1s - loss: 0.3169 - acc: 0.8659\n",
      "Epoch 27/100\n",
      "40455/40455 - 1s - loss: 0.3164 - acc: 0.8653\n",
      "Epoch 28/100\n",
      "40455/40455 - 1s - loss: 0.3154 - acc: 0.8671\n",
      "Epoch 29/100\n",
      "40455/40455 - 1s - loss: 0.3155 - acc: 0.8658\n",
      "Epoch 30/100\n",
      "40455/40455 - 1s - loss: 0.3152 - acc: 0.8661\n",
      "Epoch 31/100\n",
      "40455/40455 - 1s - loss: 0.3145 - acc: 0.8666\n",
      "Epoch 32/100\n",
      "40455/40455 - 1s - loss: 0.3148 - acc: 0.8670\n",
      "Epoch 33/100\n",
      "40455/40455 - 1s - loss: 0.3139 - acc: 0.8670\n",
      "Epoch 34/100\n",
      "40455/40455 - 1s - loss: 0.3140 - acc: 0.8653\n",
      "Epoch 35/100\n",
      "40455/40455 - 1s - loss: 0.3137 - acc: 0.8671\n",
      "Epoch 36/100\n",
      "40455/40455 - 1s - loss: 0.3134 - acc: 0.8656\n",
      "Epoch 37/100\n",
      "40455/40455 - 1s - loss: 0.3131 - acc: 0.8672\n",
      "Epoch 38/100\n",
      "40455/40455 - 1s - loss: 0.3137 - acc: 0.8654\n",
      "Epoch 39/100\n",
      "40455/40455 - 1s - loss: 0.3121 - acc: 0.8667\n",
      "Epoch 40/100\n",
      "40455/40455 - 1s - loss: 0.3129 - acc: 0.8675\n",
      "Epoch 41/100\n",
      "40455/40455 - 1s - loss: 0.3124 - acc: 0.8658\n",
      "Epoch 42/100\n",
      "40455/40455 - 1s - loss: 0.3116 - acc: 0.8672\n",
      "Epoch 43/100\n",
      "40455/40455 - 1s - loss: 0.3124 - acc: 0.8654\n",
      "Epoch 44/100\n",
      "40455/40455 - 1s - loss: 0.3123 - acc: 0.8663\n",
      "Epoch 45/100\n",
      "40455/40455 - 1s - loss: 0.3118 - acc: 0.8661\n",
      "Epoch 46/100\n",
      "40455/40455 - 1s - loss: 0.3106 - acc: 0.8683\n",
      "Epoch 47/100\n",
      "40455/40455 - 1s - loss: 0.3120 - acc: 0.8659\n",
      "Epoch 48/100\n",
      "40455/40455 - 1s - loss: 0.3112 - acc: 0.8677\n",
      "Epoch 49/100\n",
      "40455/40455 - 1s - loss: 0.3106 - acc: 0.8665\n",
      "Epoch 50/100\n",
      "40455/40455 - 1s - loss: 0.3113 - acc: 0.8663\n",
      "Epoch 51/100\n",
      "40455/40455 - 1s - loss: 0.3111 - acc: 0.8675\n",
      "Epoch 52/100\n",
      "40455/40455 - 1s - loss: 0.3104 - acc: 0.8657\n",
      "Epoch 53/100\n",
      "40455/40455 - 1s - loss: 0.3098 - acc: 0.8666\n",
      "Epoch 54/100\n",
      "40455/40455 - 1s - loss: 0.3107 - acc: 0.8666\n",
      "Epoch 55/100\n",
      "40455/40455 - 1s - loss: 0.3098 - acc: 0.8672\n",
      "Epoch 56/100\n",
      "40455/40455 - 1s - loss: 0.3097 - acc: 0.8674\n",
      "Epoch 57/100\n",
      "40455/40455 - 1s - loss: 0.3096 - acc: 0.8672\n",
      "Epoch 58/100\n",
      "40455/40455 - 1s - loss: 0.3094 - acc: 0.8673\n",
      "Epoch 59/100\n",
      "40455/40455 - 1s - loss: 0.3087 - acc: 0.8672\n",
      "Epoch 60/100\n",
      "40455/40455 - 1s - loss: 0.3090 - acc: 0.8674\n",
      "Epoch 61/100\n",
      "40455/40455 - 1s - loss: 0.3080 - acc: 0.8686\n",
      "Epoch 62/100\n",
      "40455/40455 - 1s - loss: 0.3083 - acc: 0.8665\n",
      "Epoch 63/100\n",
      "40455/40455 - 1s - loss: 0.3086 - acc: 0.8652\n",
      "Epoch 64/100\n",
      "40455/40455 - 1s - loss: 0.3088 - acc: 0.8678\n",
      "Epoch 65/100\n",
      "40455/40455 - 1s - loss: 0.3074 - acc: 0.8684\n",
      "Epoch 66/100\n",
      "40455/40455 - 1s - loss: 0.3088 - acc: 0.8670\n",
      "Epoch 67/100\n",
      "40455/40455 - 1s - loss: 0.3085 - acc: 0.8664\n",
      "Epoch 68/100\n",
      "40455/40455 - 1s - loss: 0.3076 - acc: 0.8684\n",
      "Epoch 69/100\n",
      "40455/40455 - 1s - loss: 0.3078 - acc: 0.8664\n",
      "Epoch 70/100\n",
      "40455/40455 - 1s - loss: 0.3075 - acc: 0.8679\n",
      "Epoch 71/100\n",
      "40455/40455 - 1s - loss: 0.3071 - acc: 0.8681\n",
      "Epoch 72/100\n",
      "40455/40455 - 1s - loss: 0.3075 - acc: 0.8673\n",
      "Epoch 73/100\n",
      "40455/40455 - 1s - loss: 0.3068 - acc: 0.8687\n",
      "Epoch 74/100\n",
      "40455/40455 - 1s - loss: 0.3074 - acc: 0.8667\n",
      "Epoch 75/100\n",
      "40455/40455 - 1s - loss: 0.3079 - acc: 0.8664\n",
      "Epoch 76/100\n",
      "40455/40455 - 1s - loss: 0.3069 - acc: 0.8674\n",
      "Epoch 77/100\n",
      "40455/40455 - 1s - loss: 0.3071 - acc: 0.8676\n",
      "Epoch 78/100\n",
      "40455/40455 - 1s - loss: 0.3068 - acc: 0.8685\n",
      "Epoch 79/100\n",
      "40455/40455 - 1s - loss: 0.3066 - acc: 0.8678\n",
      "Epoch 80/100\n",
      "40455/40455 - 1s - loss: 0.3070 - acc: 0.8679\n",
      "Epoch 81/100\n",
      "40455/40455 - 1s - loss: 0.3062 - acc: 0.8682\n",
      "Epoch 82/100\n",
      "40455/40455 - 1s - loss: 0.3063 - acc: 0.8680\n",
      "Epoch 83/100\n",
      "40455/40455 - 1s - loss: 0.3069 - acc: 0.8687\n",
      "Epoch 84/100\n",
      "40455/40455 - 1s - loss: 0.3064 - acc: 0.8663\n",
      "Epoch 85/100\n",
      "40455/40455 - 1s - loss: 0.3059 - acc: 0.8682\n",
      "Epoch 86/100\n",
      "40455/40455 - 1s - loss: 0.3054 - acc: 0.8691\n",
      "Epoch 87/100\n",
      "40455/40455 - 1s - loss: 0.3058 - acc: 0.8686\n",
      "Epoch 88/100\n",
      "40455/40455 - 1s - loss: 0.3064 - acc: 0.8677\n",
      "Epoch 89/100\n",
      "40455/40455 - 1s - loss: 0.3058 - acc: 0.8680\n",
      "Epoch 90/100\n",
      "40455/40455 - 1s - loss: 0.3060 - acc: 0.8676\n",
      "Epoch 91/100\n",
      "40455/40455 - 1s - loss: 0.3046 - acc: 0.8694\n",
      "Epoch 92/100\n",
      "40455/40455 - 1s - loss: 0.3067 - acc: 0.8671\n",
      "Epoch 93/100\n",
      "40455/40455 - 1s - loss: 0.3059 - acc: 0.8687\n",
      "Epoch 94/100\n",
      "40455/40455 - 1s - loss: 0.3056 - acc: 0.8684\n",
      "Epoch 95/100\n",
      "40455/40455 - 1s - loss: 0.3067 - acc: 0.8670\n",
      "Epoch 96/100\n",
      "40455/40455 - 1s - loss: 0.3055 - acc: 0.8671\n",
      "Epoch 97/100\n",
      "40455/40455 - 1s - loss: 0.3059 - acc: 0.8663\n",
      "Epoch 98/100\n",
      "40455/40455 - 1s - loss: 0.3056 - acc: 0.8692\n",
      "Epoch 99/100\n",
      "40455/40455 - 1s - loss: 0.3064 - acc: 0.8678\n",
      "Epoch 100/100\n",
      "40455/40455 - 1s - loss: 0.3052 - acc: 0.8691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f71c6a28d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40455/40455 - 1s - loss: 0.3000 - acc: 0.8710\n",
      "Normal Neural Network - Loss: 0.2999517162121531, Accuracy: 0.8710171580314636\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_train_scaled, y_train_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13485/13485 - 0s - loss: 0.3248 - acc: 0.8666\n",
      "Normal Neural Network - Loss: 0.32482521970668987, Accuracy: 0.866592526435852\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
